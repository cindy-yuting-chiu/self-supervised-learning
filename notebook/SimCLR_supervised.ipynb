{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Setup\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ocZ1vq4eQWQj",
        "outputId": "e8f1271e-4fbd-4d83-8261-de4f75705eb8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Archive:  tools.zip\n",
            "   creating: tools/\n",
            "  inflating: tools/utils.py          \n",
            "   creating: tools/.ipynb_checkpoints/\n",
            "  inflating: tools/.ipynb_checkpoints/dataset-checkpoint.py  \n",
            "   creating: tools/__pycache__/\n",
            "  inflating: tools/__pycache__/utils.cpython-38.pyc  \n",
            "  inflating: tools/__pycache__/dataset.cpython-38.pyc  \n",
            "  inflating: tools/dataset.py        \n"
          ]
        }
      ],
      "source": [
        "# import necessary dependencies\n",
        "import argparse\n",
        "import os, sys\n",
        "import time\n",
        "import datetime\n",
        "from tqdm import tqdm_notebook as tqdm\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "\n",
        "from torchvision import datasets, transforms\n",
        "import torchvision\n",
        "\n",
        "from torch.utils.data import DataLoader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "GUg2OcZ5QcvF"
      },
      "outputs": [],
      "source": [
        "\n",
        "###################### Data Preprocessing #######################\n",
        "\n",
        "\n",
        "train_transform = transforms.Compose([\n",
        "            # make sure we're using PIL instead of tensor when doing other transform \n",
        "            transforms.RandomCrop(32, 4),\n",
        "            #transforms.GaussianBlur(23, sigma=(0.1, 2.0)), # CIFAR 10 doesn't use gaussian blur\n",
        "            #transforms.RandomResizedCrop(size=32,scale=(0.08,0.1),ratio=(0.75,1.33)),\n",
        "            transforms.RandomHorizontalFlip(p=0.5),\n",
        "            #get_color_distortion(),\n",
        "            transforms.ToTensor(),\n",
        "            # the normalize numbers are from previous assignment\n",
        "            transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
        "            ])\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "_gI40kWGM5RU"
      },
      "outputs": [],
      "source": [
        "linear_eval_transform_test = transforms.Compose([\n",
        "            #transforms.GaussianBlur(23, sigma=(0.1, 2.0)), # CIFAR 10 doesn't use gaussian blur\n",
        "            transforms.RandomResizedCrop(size=32,scale=(0.08,0.1),ratio=(0.75,1.33)),\n",
        "            transforms.ToTensor(),\n",
        "            # the normalize numbers are from previous assignment\n",
        "            # transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
        "            ])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 101,
          "referenced_widgets": [
            "97aa121bb5b04f2197e3f9cc6e211de6",
            "6411c92fdfc0464491bad3032cf2a4d0",
            "c7b2ff9c96da48ffac1d823c99ecb657",
            "873ca1f241394f979ea94e7ad8359f12",
            "d3e64638fcc049d081cfd8204af498d8",
            "56cc48e5265b4be59d32ea130c2d1148",
            "3057155634c44c89b3647eb5882d04b1",
            "555ac66268f24bf4b5e9b605e1e87aa3",
            "d8f1ea0f0f43461e8dff89cce2b7261d",
            "0ae261c70a224eb5abe1ae01bbe94518",
            "808c3e293d2b4079ab015763b9aefd35"
          ]
        },
        "id": "En5WfePqMvaI",
        "outputId": "dc7607d1-6dee-451a-acfc-3476f6997f75"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data7/cifar-10-python.tar.gz\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "97aa121bb5b04f2197e3f9cc6e211de6",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/170498071 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Extracting ./data7/cifar-10-python.tar.gz to ./data7\n",
            "Files already downloaded and verified\n"
          ]
        }
      ],
      "source": [
        "# load and split data \n",
        "BATCH_SIZE = 128\n",
        "\n",
        "#all_train_cifar = datasets.CIFAR10('./data7', train=True, download=True, transform=transforms.Compose(\n",
        "#    [transforms.ToTensor(), transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))]))\n",
        "#further split train and validation set \n",
        "\n",
        "all_train_cifar = datasets.CIFAR10('./data7', train=True, download=True, transform=train_transform)\n",
        "\n",
        "train_set, val_set = torch.utils.data.random_split(all_train_cifar, [45000, 5000])\n",
        "\n",
        "\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(\n",
        "    train_set,\n",
        "    batch_size = BATCH_SIZE, shuffle=True, )\n",
        "\n",
        "val_loader = torch.utils.data.DataLoader(\n",
        "    val_set,\n",
        "    batch_size = BATCH_SIZE, shuffle=True, )\n",
        "\n",
        "# the testset don't have data augmentation\n",
        "test_loader = torch.utils.data.DataLoader(\n",
        "    datasets.CIFAR10('./data7', train=False, download=True, transform=linear_eval_transform_test),\n",
        "    batch_size = BATCH_SIZE, shuffle=True, )\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EiUMHCUvHhu0"
      },
      "outputs": [],
      "source": [
        " \n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(device)     "
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "GsZfkFgfTGbD"
      },
      "outputs": [],
      "source": [
        "\n",
        "class Block(nn.Module):\n",
        "  def __init__(self, in_c: int, out_c: int, s: int):\n",
        "    \"\"\"\n",
        "    A Block Model that takes in a few arguments. This will represent 1 block in the ResNet layer\n",
        "    It should have 2 convoluational layer in each block\n",
        "    1. in_c will indicate the number of input features \n",
        "    2. out_c will indicate the number of desired output features\n",
        "    3. s will indicate the number of stride of the first conv layer in the block, it's also an\n",
        "    indicator of whether the block is performing downsampling. \n",
        "    \"\"\"\n",
        "    super(Block, self).__init__()\n",
        "    self.conv1 = nn.Conv2d(in_channels = in_c, out_channels = out_c, kernel_size = 3, stride= s, padding = 1)\n",
        "    self.conv1_bn = nn.BatchNorm2d(out_c)\n",
        "    self.conv2 = nn.Conv2d(in_channels = out_c, out_channels = out_c, kernel_size = 3, stride=1, padding = 1)\n",
        "    self.conv2_bn = nn.BatchNorm2d(out_c)\n",
        "    # if this is the first block in the layer (2nd & 3rd), we want to resize the identity\n",
        "    # when stride !=1, that means we're downsampling in the first block of the layer\n",
        "    self.identity = nn.Sequential() # if not downsample layer, then do nothing\n",
        "    if s!=1: \n",
        "      self.identity = nn.Sequential(\n",
        "          # we use option b 1x1 conv here\n",
        "          nn.Conv2d(in_channels = in_c, out_channels = out_c, kernel_size = 1 , stride = 2, padding = 0),\n",
        "          nn.BatchNorm2d(out_c)\n",
        "      )\n",
        "\n",
        "  def forward(self, x):  \n",
        "    out = self.conv1(x)\n",
        "    out = self.conv1_bn(out)\n",
        "    out = F.relu(out)\n",
        "    out = self.conv2(out)\n",
        "    out = self.conv2_bn(out)\n",
        "    # add in the identity here (make sure the size is correct)\n",
        "    out += self.identity(x)\n",
        "    out = F.relu(out)\n",
        "    return out \n",
        "\n",
        "\n",
        "class ResNet18_pred(nn.Module):\n",
        "    def __init__(self, in_c, resblock):\n",
        "      \"\"\"\n",
        "      This is the model that is representing the ResNet 20 archieture\n",
        "      It should have 20 layers in total.\n",
        "      1. in_c will indicate the image input feature channel number\n",
        "      2. resblock will indicatet the Block that we created previously\n",
        "      \"\"\"\n",
        "      super(ResNet18_pred, self).__init__()\n",
        "\n",
        "      # layer 0 \n",
        "      # skip maxpooling in the first conv\n",
        "      self.conv1 = nn.Conv2d(in_channels = in_c, out_channels = 64, kernel_size = 3, stride=1, padding= 1)\n",
        "      self.conv1_bn = nn.BatchNorm2d(64)\n",
        "      # define layers \n",
        "      self.layer1= nn.Sequential(\n",
        "            resblock(in_c = 64, out_c = 64, s = 1),\n",
        "            resblock(in_c = 64, out_c = 64, s = 1),\n",
        "        )\n",
        "      #downsampling layer\n",
        "      self.layer2 = nn.Sequential(\n",
        "            resblock(in_c = 64, out_c = 128, s = 2),\n",
        "            resblock(in_c = 128, out_c = 128, s = 1),\n",
        "        )\n",
        "      #downsampling layer\n",
        "      self.layer3 = nn.Sequential(\n",
        "            resblock(in_c = 128, out_c = 256, s = 2),\n",
        "            resblock(in_c = 256, out_c = 256, s = 1),\n",
        "        )\n",
        "      #downsampling layer\n",
        "      self.layer4 = nn.Sequential(\n",
        "            resblock(in_c = 256, out_c = 512, s = 2),\n",
        "            resblock(in_c = 512, out_c = 512, s = 1),\n",
        "        )\n",
        "      \n",
        "      self.linear = nn.Linear(512, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "      # first conv\n",
        "      out = self.conv1(x)\n",
        "      out = self.conv1_bn(out)\n",
        "      out = F.relu(out)\n",
        "      # first layer\n",
        "      out = self.layer1(out)\n",
        "      # second layer\n",
        "      out = self.layer2(out)\n",
        "      # third layer\n",
        "      out = self.layer3(out)\n",
        "      # fourth layer \n",
        "      out = self.layer4(out)\n",
        "\n",
        "      # apply avg pooling\n",
        "      out = F.avg_pool2d(out, out.size()[3])\n",
        "      # out = self.mlp(out)\n",
        "      out = out.view(out.size(0), -1)\n",
        "      out = self.linear(out)\n",
        "      #out = self.linear(out)\n",
        "      return out"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Model Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "2SpjD8mBHIBU"
      },
      "outputs": [],
      "source": [
        "# some hyperparameters\n",
        "# total number of training epochs\n",
        "\n",
        "def training_epochs(lr, model,filename, EPOCHS, DECAY_EPOCHS, DECAY):\n",
        "  #EPOCHS = 30\n",
        "  # the folder where the trained model is saved\n",
        "  CHECKPOINT_FOLDER = \"./saved_model\"\n",
        "  # start the training/validation process\n",
        "  # the process should take about 5 minutes on a GTX 1070-Ti\n",
        "  # if the code is written efficiently.\n",
        "  best_val_acc = 0\n",
        "  current_learning_rate = lr\n",
        "\n",
        "  print(\"==> Training starts!\")\n",
        "  print(\"=\"*50)\n",
        "  for i in range(0, EPOCHS):\n",
        "      # handle the learning rate scheduler.\n",
        "      \n",
        "      if i % DECAY_EPOCHS == 0 and i != 0:\n",
        "          current_learning_rate = current_learning_rate * DECAY\n",
        "          for param_group in optimizer.param_groups:\n",
        "              param_group['lr'] = current_learning_rate\n",
        "          print(\"Current learning rate has decayed to %f\" %current_learning_rate)\n",
        "      #######################\n",
        "      # your code here\n",
        "      # switch to train mode\n",
        "      \n",
        "      model.train()\n",
        "      #######################\n",
        "      \n",
        "      print(\"Epoch %d:\" %i)\n",
        "      # this help you compute the training accuracy\n",
        "      total_examples = 0\n",
        "      correct_examples = 0\n",
        "\n",
        "      train_loss = 0 # track training loss if you want\n",
        "      \n",
        "      # Train the model for 1 epoch.\n",
        "      for batch_idx, (inputs, targets) in enumerate(train_loader):\n",
        "          ####################################\n",
        "          # your code here\n",
        "          # copy inputs to device\n",
        "          inputs, targets = inputs.to(device), targets.to(device)\n",
        "\n",
        "          # compute the output and loss\n",
        "          outputs = model(inputs)\n",
        "          loss = criterion(outputs, targets)\n",
        "          train_loss += loss    \n",
        "\n",
        "          # zero the gradient\n",
        "          optimizer.zero_grad()\n",
        "  \n",
        "          # backpropagation\n",
        "          loss.backward()\n",
        "  \n",
        "          # apply gradient and update the weights\n",
        "          optimizer.step()\n",
        "          \n",
        "          # count the number of correctly predicted samples in the current batch\n",
        "          outputs = model(inputs)\n",
        "          _, predicted = torch.max(outputs.data, 1)\n",
        "          total_examples += targets.size(0)\n",
        "          correct_examples += (predicted == targets).sum().item()\n",
        "\n",
        "          ####################################\n",
        "                  \n",
        "      avg_loss = train_loss / len(train_loader)\n",
        "      avg_acc = correct_examples / total_examples\n",
        "      print(\"Training loss: %.4f, Training accuracy: %.4f\" %(avg_loss, avg_acc))\n",
        "\n",
        "      # Validate on the validation dataset\n",
        "      #######################\n",
        "      # your code here\n",
        "      # switch to eval mode\n",
        "      model.eval()\n",
        "      \n",
        "      #######################\n",
        "\n",
        "      # this help you compute the validation accuracy\n",
        "      total_examples = 0\n",
        "      correct_examples = 0\n",
        "      \n",
        "      val_loss = 0 # again, track the validation loss if you want\n",
        "\n",
        "      # disable gradient during validation, which can save GPU memory\n",
        "      with torch.no_grad():\n",
        "          for batch_idx, (inputs, targets) in enumerate(val_loader):\n",
        "              ####################################\n",
        "              # your code here\n",
        "              # copy inputs to device\n",
        "              inputs, targets = inputs.to(device), targets.to(device)\n",
        "\n",
        "              \n",
        "              # compute the output and loss\n",
        "              outputs = model(inputs)\n",
        "              loss = criterion(outputs, targets)\n",
        "              val_loss += loss\n",
        "              \n",
        "              # count the number of correctly predicted samples in the current batch\n",
        "              outputs = model(inputs)\n",
        "              _, predicted = torch.max(outputs.data, 1)\n",
        "              total_examples += targets.size(0)\n",
        "              correct_examples += (predicted == targets).sum().item()\n",
        "              ####################################\n",
        "\n",
        "      avg_loss = val_loss / len(val_loader)\n",
        "      avg_acc = correct_examples / total_examples\n",
        "      print(\"Validation loss: %.4f, Validation accuracy: %.4f\" % (avg_loss, avg_acc))\n",
        "      \n",
        "      # save the model checkpoint\n",
        "      if avg_acc > best_val_acc:\n",
        "          best_val_acc = avg_acc\n",
        "          if not os.path.exists(CHECKPOINT_FOLDER):\n",
        "              os.makedirs(CHECKPOINT_FOLDER)\n",
        "          print(\"Saving ...\")\n",
        "          state = {'state_dict': model.state_dict(),\n",
        "                   'epoch': i,\n",
        "                   'lr': current_learning_rate}\n",
        "          torch.save(state, os.path.join(CHECKPOINT_FOLDER, filename+'_test.pth'))\n",
        "          \n",
        "      print('')\n",
        "\n",
        "  print(\"=\"*50)\n",
        "  print(f\"==> Optimization finished! Best validation accuracy: {best_val_acc:.4f}\")\n",
        "  return best_val_acc, val_loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C1a-nLSNIGDH",
        "outputId": "b9354e9c-c651-44e2-91fb-df67b2fc55a9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "==> Training starts!\n",
            "==================================================\n",
            "Epoch 0:\n",
            "Training loss: 1.4538, Training accuracy: 0.5206\n",
            "Validation loss: 1.1535, Validation accuracy: 0.5906\n",
            "Saving ...\n",
            "\n",
            "Epoch 1:\n",
            "Training loss: 0.9655, Training accuracy: 0.6962\n",
            "Validation loss: 0.8902, Validation accuracy: 0.6926\n",
            "Saving ...\n",
            "\n",
            "Epoch 2:\n",
            "Training loss: 0.7468, Training accuracy: 0.7745\n",
            "Validation loss: 0.7587, Validation accuracy: 0.7374\n",
            "Saving ...\n",
            "\n",
            "Epoch 3:\n",
            "Training loss: 0.6291, Training accuracy: 0.8140\n",
            "Validation loss: 0.6412, Validation accuracy: 0.7744\n",
            "Saving ...\n",
            "\n",
            "Epoch 4:\n",
            "Training loss: 0.5454, Training accuracy: 0.8431\n",
            "Validation loss: 0.5272, Validation accuracy: 0.8160\n",
            "Saving ...\n",
            "\n",
            "Epoch 5:\n",
            "Training loss: 0.4857, Training accuracy: 0.8631\n",
            "Validation loss: 0.5354, Validation accuracy: 0.8092\n",
            "\n",
            "Epoch 6:\n",
            "Training loss: 0.4368, Training accuracy: 0.8791\n",
            "Validation loss: 0.5562, Validation accuracy: 0.8092\n",
            "\n",
            "Epoch 7:\n",
            "Training loss: 0.4052, Training accuracy: 0.8895\n",
            "Validation loss: 0.5214, Validation accuracy: 0.8144\n",
            "\n",
            "Epoch 8:\n",
            "Training loss: 0.3712, Training accuracy: 0.9016\n",
            "Validation loss: 0.4610, Validation accuracy: 0.8388\n",
            "Saving ...\n",
            "\n",
            "Epoch 9:\n",
            "Training loss: 0.3451, Training accuracy: 0.9107\n",
            "Validation loss: 0.4494, Validation accuracy: 0.8542\n",
            "Saving ...\n",
            "\n",
            "==================================================\n",
            "==> Optimization finished! Best validation accuracy: 0.8542\n"
          ]
        }
      ],
      "source": [
        "net = ResNet18_pred(in_c =3 , resblock = Block)\n",
        "net = net.to(device)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(net.parameters(), lr=0.01, momentum=MOMENTUM ,weight_decay= 5e-5)\n",
        "output = training_epochs(0.01, net , 'resnet20_3', 10, 80, 0.1)\n",
        "#val_acc_list.append(output[0])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Eyvr72XZMIjj",
        "outputId": "fb00b7a6-85fa-4fb8-b38a-cd9cae6c7d32"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "==> Training starts!\n",
            "==================================================\n",
            "Epoch 0:\n",
            "Training loss: 1.3171, Training accuracy: 0.5778\n",
            "Validation loss: 1.0074, Validation accuracy: 0.6372\n",
            "Saving ...\n",
            "\n",
            "Epoch 1:\n",
            "Training loss: 0.7780, Training accuracy: 0.7736\n",
            "Validation loss: 0.7137, Validation accuracy: 0.7528\n",
            "Saving ...\n",
            "\n",
            "Epoch 2:\n",
            "Training loss: 0.5473, Training accuracy: 0.8573\n",
            "Validation loss: 0.7370, Validation accuracy: 0.7520\n",
            "\n",
            "Epoch 3:\n",
            "Training loss: 0.3866, Training accuracy: 0.9182\n",
            "Validation loss: 0.6502, Validation accuracy: 0.7888\n",
            "Saving ...\n",
            "\n",
            "Epoch 4:\n",
            "Training loss: 0.2579, Training accuracy: 0.9640\n",
            "Validation loss: 0.6399, Validation accuracy: 0.8040\n",
            "Saving ...\n",
            "\n",
            "Epoch 5:\n",
            "Training loss: 0.1706, Training accuracy: 0.9859\n",
            "Validation loss: 0.8084, Validation accuracy: 0.7818\n",
            "\n",
            "Epoch 6:\n",
            "Training loss: 0.1052, Training accuracy: 0.9953\n",
            "Validation loss: 0.7725, Validation accuracy: 0.8092\n",
            "Saving ...\n",
            "\n",
            "Epoch 7:\n",
            "Training loss: 0.0702, Training accuracy: 0.9987\n",
            "Validation loss: 0.8274, Validation accuracy: 0.7950\n",
            "\n",
            "Epoch 8:\n",
            "Training loss: 0.0550, Training accuracy: 0.9991\n",
            "Validation loss: 0.8370, Validation accuracy: 0.7978\n",
            "\n",
            "Epoch 9:\n",
            "Training loss: 0.0328, Training accuracy: 0.9998\n",
            "Validation loss: 0.8794, Validation accuracy: 0.8102\n",
            "Saving ...\n",
            "\n",
            "==================================================\n",
            "==> Optimization finished! Best validation accuracy: 0.8102\n"
          ]
        }
      ],
      "source": [
        "net = ResNet18_pred(in_c =3 , resblock = Block)\n",
        "net = net.to(device)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(net.parameters(), lr=0.01, momentum=MOMENTUM ,weight_decay= 5e-5)\n",
        "output = training_epochs(0.01, net , 'resnet20_2_', 10, 80, 0.1)\n",
        "#val_acc_list.append(output[0])\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Testing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "L7IlcbRPKTQm"
      },
      "outputs": [],
      "source": [
        "test = ResNet18_pred(3, Block) \n",
        "test.load_state_dict(torch.load(\"/content/saved_model/resnet20_3__test.pth\")['state_dict'])\n",
        "test.to(device)\n",
        "test.eval()\n",
        "for parameter in test.parameters():\n",
        "    parameter.requires_grad = False"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "hgw1OL5CKX-2"
      },
      "outputs": [],
      "source": [
        "def test_model(mdl, loader):\n",
        "    mdl.eval()\n",
        "    running_correct = 0.\n",
        "    running_loss = 0.\n",
        "    running_total = 0.\n",
        "    with torch.no_grad():\n",
        "        for data,labels in loader:\n",
        "            data = data.to(device); labels = labels.to(device)\n",
        "            outputs = mdl(data)\n",
        "            loss = F.cross_entropy(outputs, labels)\n",
        "            _, preds = outputs.max(1)\n",
        "            running_correct += preds.eq(labels).sum().item()\n",
        "            running_loss += loss.item()\n",
        "            running_total += labels.size(0)\n",
        "    test_acc = running_correct/running_total\n",
        "    test_loss = running_loss/len(loader)\n",
        "    mdl.train()\n",
        "    print\n",
        "    return test_acc, test_loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UqXCi0QvKki6",
        "outputId": "850a71d5-b600-471c-d92a-7d71581db64c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(0.8028, 0.8995775078670888)"
            ]
          },
          "execution_count": 32,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "test_model(test, test_loader)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "0ae261c70a224eb5abe1ae01bbe94518": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3057155634c44c89b3647eb5882d04b1": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "555ac66268f24bf4b5e9b605e1e87aa3": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "56cc48e5265b4be59d32ea130c2d1148": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6411c92fdfc0464491bad3032cf2a4d0": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_56cc48e5265b4be59d32ea130c2d1148",
            "placeholder": "​",
            "style": "IPY_MODEL_3057155634c44c89b3647eb5882d04b1",
            "value": "100%"
          }
        },
        "808c3e293d2b4079ab015763b9aefd35": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "873ca1f241394f979ea94e7ad8359f12": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0ae261c70a224eb5abe1ae01bbe94518",
            "placeholder": "​",
            "style": "IPY_MODEL_808c3e293d2b4079ab015763b9aefd35",
            "value": " 170498071/170498071 [00:03&lt;00:00, 64658813.87it/s]"
          }
        },
        "97aa121bb5b04f2197e3f9cc6e211de6": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_6411c92fdfc0464491bad3032cf2a4d0",
              "IPY_MODEL_c7b2ff9c96da48ffac1d823c99ecb657",
              "IPY_MODEL_873ca1f241394f979ea94e7ad8359f12"
            ],
            "layout": "IPY_MODEL_d3e64638fcc049d081cfd8204af498d8"
          }
        },
        "c7b2ff9c96da48ffac1d823c99ecb657": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_555ac66268f24bf4b5e9b605e1e87aa3",
            "max": 170498071,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_d8f1ea0f0f43461e8dff89cce2b7261d",
            "value": 170498071
          }
        },
        "d3e64638fcc049d081cfd8204af498d8": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d8f1ea0f0f43461e8dff89cce2b7261d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
