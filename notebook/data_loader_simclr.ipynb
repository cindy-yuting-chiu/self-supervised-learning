{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W7aNXzLnXleO",
        "outputId": "78dbfeb9-13be-4871-f451-8b0013935323"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content/drive/MyDrive/ecehw/project\n"
          ]
        }
      ],
      "source": [
        "%cd '/content/drive/MyDrive/ecehw/project'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TE_7CfjyQPQK",
        "outputId": "6127a36e-cc7e-42a7-953c-be07011b2fba"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "device: cuda\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import random\n",
        "\n",
        "from resnet import ResNet18, MLP, Block\n",
        "\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(\"device:\", device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pKQXL819Ocrj",
        "outputId": "65cf2552-2c11-48a3-eb49-4110d52b25f9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files already downloaded and verified\n"
          ]
        }
      ],
      "source": [
        "BATCH_SIZE = 512\n",
        "\n",
        "trainset = torch.utils.data.DataLoader(\n",
        "    datasets.CIFAR10('./data', train=True, download=True, transform=transforms.ToTensor()),\n",
        "    batch_size = BATCH_SIZE, shuffle=True, )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "RgF57_f3Sw8N"
      },
      "outputs": [],
      "source": [
        "def get_color_distortion(s:float=0.5):\n",
        "    \"\"\"\n",
        "    Function from the paper that create color distortion \n",
        "    s: float, the strength of color distortion, for CIFAR 10, the paper use 0.5\n",
        "    \"\"\"\n",
        "    color_jitter = transforms.ColorJitter(0.8*s, 0.8*s, 0.8*s, 0.2*s)\n",
        "    rnd_color_jitter = transforms.RandomApply([color_jitter], p=0.8)\n",
        "    rnd_gray = transforms.RandomGrayscale(p=0.2)\n",
        "    color_distort = transforms.Compose([rnd_color_jitter, rnd_gray])\n",
        "    return color_distort"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "6mobadHTSyVI"
      },
      "outputs": [],
      "source": [
        "train_transform = transforms.Compose([\n",
        "            # make sure we're using PIL instead of tensor when doing other transform \n",
        "            transforms.ToPILImage(),\n",
        "            #transforms.GaussianBlur(23, sigma=(0.1, 2.0)), # CIFAR 10 doesn't use gaussian blur\n",
        "            transforms.RandomResizedCrop(size=32,scale=(0.08,0.1),ratio=(0.75,1.33)),\n",
        "            transforms.RandomHorizontalFlip(p=0.5),\n",
        "            get_color_distortion(),\n",
        "            transforms.ToTensor(),\n",
        "            # the normalize numbers are from previous assignment\n",
        "            transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
        "            ])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cxUPRNVOYQ-M",
        "outputId": "c5c33462-d604-48b6-8b38-459ef3555267"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Sequential(\n",
              "  (0): ResNet18(\n",
              "    (conv1): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (conv1_bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (layer1): Sequential(\n",
              "      (0): Block(\n",
              "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        (conv1_bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        (conv2_bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (identity): Sequential()\n",
              "      )\n",
              "      (1): Block(\n",
              "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        (conv1_bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        (conv2_bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (identity): Sequential()\n",
              "      )\n",
              "    )\n",
              "    (layer2): Sequential(\n",
              "      (0): Block(\n",
              "        (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
              "        (conv1_bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        (conv2_bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (identity): Sequential(\n",
              "          (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2))\n",
              "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "      )\n",
              "      (1): Block(\n",
              "        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        (conv1_bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        (conv2_bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (identity): Sequential()\n",
              "      )\n",
              "    )\n",
              "    (layer3): Sequential(\n",
              "      (0): Block(\n",
              "        (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
              "        (conv1_bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        (conv2_bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (identity): Sequential(\n",
              "          (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2))\n",
              "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "      )\n",
              "      (1): Block(\n",
              "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        (conv1_bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        (conv2_bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (identity): Sequential()\n",
              "      )\n",
              "    )\n",
              "    (layer4): Sequential(\n",
              "      (0): Block(\n",
              "        (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
              "        (conv1_bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        (conv2_bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (identity): Sequential(\n",
              "          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2))\n",
              "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "      )\n",
              "      (1): Block(\n",
              "        (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        (conv1_bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        (conv2_bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (identity): Sequential()\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (1): MLP(\n",
              "    (mlp): Sequential(\n",
              "      (0): Linear(in_features=512, out_features=512, bias=True)\n",
              "      (1): ReLU()\n",
              "      (2): Linear(in_features=512, out_features=128, bias=True)\n",
              "    )\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "LR = 0.1\n",
        "\n",
        "net_f = ResNet18(3, Block)\n",
        "net_g = MLP(512)\n",
        "net = nn.Sequential(net_f, net_g)\n",
        "optimizer = optim.Adam(net.parameters(), lr=0.0003*(BATCH_SIZE / 256), weight_decay=1e-6)\n",
        "# optimizer = optim.SGD(net.parameters(), lr=0.3*(BATCH_SIZE / 256), weight_decay=1e-6)\n",
        "# optimizer = optim.SGD(net.parameters(), lr=LR, weight_decay=1e-6)\n",
        "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=150, gamma=0.1)\n",
        "net.to(device)\n",
        "net.train()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "bqhu4T1BY5Td"
      },
      "outputs": [],
      "source": [
        "def compute_loss(yhat, t):\n",
        "    \"\"\"\n",
        "    Computing the contrastive loss based on cosine similarity\n",
        "    input:\n",
        "        yhat: [tensor] latent embedding features size: BATCH_SIZE * 128\n",
        "        t: [float] temperature range: (0.0, 1.0)\n",
        "    output:\n",
        "        loss: [tensor] 1D\n",
        "    \"\"\"\n",
        "    \n",
        "    # testing code\n",
        "    #from collections import defaultdict\n",
        "    #cache = defaultdict(int)\n",
        "    #for i in range(yhat.shape[0]):\n",
        "    #    for j in range(i+1, yhat.shape[0]):\n",
        "    #        val = torch.nn.functional.cosine_similarity(yhat[i], yhat[j], dim=0, eps=1e-8)\n",
        "    #        cache[(i, j)] = val\n",
        "    #        cache[(j, i)] = val\n",
        "    \n",
        "    N = yhat.shape[0]\n",
        "\n",
        "    # Calculate the pair-wise consine similarity\n",
        "    cache = torch.nn.functional.cosine_similarity(yhat.unsqueeze(0), yhat.unsqueeze(1), dim=-1, eps=1e-8)\n",
        "    cache = cache / t\n",
        "    \n",
        "    # Delete the diagonal entries\n",
        "    mask = torch.eye(N, dtype=bool)\n",
        "    cache = cache[~mask].view((N, N-1))\n",
        "\n",
        "    # Make pesudo-labels\n",
        "    label = []\n",
        "    for i in range(N // 2):\n",
        "        label.append(int(2 *i))\n",
        "        label.append(int(2 *i))\n",
        "    label = torch.tensor(label)\n",
        "    label = label.to(device)\n",
        "\n",
        "    # Calculate the cross entropy loss\n",
        "    loss = F.cross_entropy(cache, label)\n",
        "\n",
        "    return loss\n",
        "    \n",
        "\n",
        "    \"\"\"\n",
        "    # Calculate the pair-wise consine similarity\n",
        "    cache = torch.nn.functional.cosine_similarity(yhat.unsqueeze(0), yhat.unsqueeze(1), dim=-1, eps=1e-8)\n",
        "    # print(cache)\n",
        "    cache = torch.exp(cache / t)\n",
        "    cache_sum = torch.sum(cache, dim=1)\n",
        "\n",
        "    \n",
        "    # Compute the contrastive loss\n",
        "    loss = 0\n",
        "    for n in range(yhat.shape[0]):\n",
        "        # Get the index of positive pairs, based on 2 tensors of the same pair are adjacent in terms of index\n",
        "        i = n\n",
        "        if i % 2 == 0:\n",
        "            j = i + 1\n",
        "        else:\n",
        "            j = i - 1\n",
        "\n",
        "        # The numerator is between the positive pair\n",
        "        # The denominator is between one tensor with all OTHER tensors\n",
        "        numerator = cache[i, j]\n",
        "        denominator = cache_sum[i] - cache[i, i]\n",
        "        #denominator = 0\n",
        "        #for k in range(yhat.shape[0]):\n",
        "        #    if k != i:\n",
        "        #        denominator += cache[i, k]\n",
        "        cur_loss = (-1) * torch.log(numerator / denominator)\n",
        "        # Add up the loss and take the average\n",
        "        loss += (1 / (2 * yhat.shape[0])) * cur_loss\n",
        "    loss = torch.tensor(loss.item())\n",
        "    loss.requires_grad = True\n",
        "    # loss = torch.mean(loss)\n",
        "    \n",
        "    return loss\n",
        "    \"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mir0ML6bQ2Jy",
        "outputId": "62783a3a-8ef8-410a-bb03-9375f1b199af"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[6.643378209094612]\n",
            "[6.643378209094612, 6.498396435562445]\n"
          ]
        }
      ],
      "source": [
        "# loop through each batch in trainset \n",
        "LOSSES = []\n",
        "EPOCHS = 10\n",
        "OPTIM_LOSS = float('inf')\n",
        "\n",
        "for epoch in range(EPOCHS):\n",
        "    cost = 0\n",
        "    for data, label in trainset:\n",
        "        for ind_img in range(len(data)): # loop through each image in batch \n",
        "            par_tensor = data[ind_img]\n",
        "            cur_tensor_0 = train_transform(par_tensor) # first aug\n",
        "            cur_tensor_1 = train_transform(par_tensor) # second aug \n",
        "            # resize \n",
        "            cur_tensor_0, cur_tensor_1 = torch.unsqueeze(cur_tensor_0, 0), torch.unsqueeze(cur_tensor_1, 0) \n",
        "            # if this is the first image in the batch, we just concat the 2 data aug \n",
        "            if ind_img == 0:\n",
        "                total_tensor = torch.cat((cur_tensor_0, cur_tensor_1), dim=0)\n",
        "            # else append to the previous augmented pair in the batch \n",
        "            else:\n",
        "                total_tensor = torch.cat((total_tensor, cur_tensor_0, cur_tensor_1), dim=0)\n",
        "            \n",
        "        total_tensor = total_tensor.to(device)\n",
        "        # pass <total_tensor> into the model \n",
        "        yhat = net(total_tensor)\n",
        "        # calculate loss \n",
        "        loss = compute_loss(yhat, 0.5)\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        scheduler.step()\n",
        "        cost += loss.item()\n",
        "        avg_loss = cost / len(trainset)\n",
        "\n",
        "    LOSSES.append(avg_loss)\n",
        "    if avg_loss < OPTIM_LOSS:\n",
        "        OPTIM_LOSS = avg_loss\n",
        "        torch.save(net.state_dict(), 'simclr.pt')\n",
        "        # torch.save(net_f.state_dict(), 'simclr_netf.pt')\n",
        "    print(LOSSES)\n",
        "        "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 169
        },
        "id": "6Wmte-NN0FAa",
        "outputId": "1d29f78a-9bfb-481b-db1b-8679e1166f08"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-6e01c96c163c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0m_\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mLOSSES\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mLOSSES\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'plt' is not defined"
          ]
        }
      ],
      "source": [
        "plt.plot([_ for _ in range(len(LOSSES))], LOSSES)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f1MYfjCMREKI"
      },
      "outputs": [],
      "source": [
        "# loop through each batch in trainset \n",
        "LOSSES = []\n",
        "#net_f.eval()\n",
        "temp = []\n",
        "\n",
        "for data, label in trainset:\n",
        "    pass"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7VoxTNVH0zLL"
      },
      "outputs": [],
      "source": [
        "# decide the learning rate, whether to implement lr decay\n",
        "# linear eval (discard net_g, connect net_f with logistic regressor, freeze net_f, train the whole net)\n",
        "# supervised counterpart, for simCLR epoch=90\n",
        "# write the report"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}