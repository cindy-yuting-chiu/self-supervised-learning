{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W7aNXzLnXleO",
        "outputId": "78dbfeb9-13be-4871-f451-8b0013935323"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content/drive/MyDrive/ecehw/project\n"
          ]
        }
      ],
      "source": [
        "%cd '/content/drive/MyDrive/ecehw/project'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TE_7CfjyQPQK",
        "outputId": "7b25cce6-95be-4225-ae4b-1d1d1b56ca92"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "device: cuda\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import random\n",
        "\n",
        "from resnet import ResNet18, MLP, Block\n",
        "\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(\"device:\", device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 103,
          "referenced_widgets": [
            "8187dac045ec45739fd72ae3d1cb46a9",
            "c9fe3685608a463e9db8b7fa50a177a5",
            "11852106ef87465a93db649d4743d634",
            "1b75618e8bdb4d1a9750daaf1138d337",
            "134178bca01a4082b84161c82eafd98c",
            "5b2f7826b2d2424cbfeffe6366e17403",
            "fe5b64ba0fc84c0e8b57dc093c8e3b7f",
            "a2cf472272c14b09a94fb4f3ba9a0c4e",
            "94570a69aab44f9293fdae90e8a3a07c",
            "2456d48dc14c4dc8aa2325d6390597bd",
            "5787f9b75b6b4bb494d83f5ba9c359f4"
          ]
        },
        "id": "pKQXL819Ocrj",
        "outputId": "8e7601f3-a43a-47af-d789-d78c84d3741b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data/cifar-10-python.tar.gz\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/170498071 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "8187dac045ec45739fd72ae3d1cb46a9"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/cifar-10-python.tar.gz to ./data\n",
            "Files already downloaded and verified\n"
          ]
        }
      ],
      "source": [
        "BATCH_SIZE = 256\n",
        "\n",
        "trainset = torch.utils.data.DataLoader(\n",
        "    datasets.CIFAR10('./data', train=True, download=True, transform=transforms.ToTensor()),\n",
        "    batch_size = BATCH_SIZE, shuffle=True, )\n",
        "\n",
        "testset = torch.utils.data.DataLoader(\n",
        "    datasets.CIFAR10('./data', train=False, download=True, transform=transforms.ToTensor()),\n",
        "    batch_size = BATCH_SIZE, shuffle=True, )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RgF57_f3Sw8N"
      },
      "outputs": [],
      "source": [
        "def get_color_distortion(s:float=0.5):\n",
        "    \"\"\"\n",
        "    Function from the paper that create color distortion \n",
        "    s: float, the strength of color distortion, for CIFAR 10, the paper use 0.5\n",
        "    \"\"\"\n",
        "    color_jitter = transforms.ColorJitter(0.8*s, 0.8*s, 0.8*s, 0.2*s)\n",
        "    rnd_color_jitter = transforms.RandomApply([color_jitter], p=0.8)\n",
        "    rnd_gray = transforms.RandomGrayscale(p=0.2)\n",
        "    color_distort = transforms.Compose([rnd_color_jitter, rnd_gray])\n",
        "    return color_distort"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6mobadHTSyVI"
      },
      "outputs": [],
      "source": [
        "train_transform = transforms.Compose([\n",
        "            # make sure we're using PIL instead of tensor when doing other transform \n",
        "            transforms.ToPILImage(),\n",
        "            #transforms.GaussianBlur(23, sigma=(0.1, 2.0)), # CIFAR 10 doesn't use gaussian blur\n",
        "            transforms.RandomResizedCrop(size=32,scale=(0.08,0.1),ratio=(0.75,1.33)),\n",
        "            transforms.RandomHorizontalFlip(p=0.5),\n",
        "            get_color_distortion(),\n",
        "            transforms.ToTensor(),\n",
        "            # the normalize numbers are from previous assignment\n",
        "            # transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
        "            ])\n",
        "\n",
        "linear_eval_transform = transforms.Compose([\n",
        "            #transforms.GaussianBlur(23, sigma=(0.1, 2.0)), # CIFAR 10 doesn't use gaussian blur\n",
        "            transforms.RandomResizedCrop(size=32,scale=(0.08,0.1),ratio=(0.75,1.33)),\n",
        "            transforms.RandomHorizontalFlip(p=0.5),\n",
        "            get_color_distortion(),\n",
        "            transforms.ToTensor(),\n",
        "            # the normalize numbers are from previous assignment\n",
        "            # transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
        "            ])\n",
        "\n",
        "linear_eval_transform_test = transforms.Compose([\n",
        "            #transforms.GaussianBlur(23, sigma=(0.1, 2.0)), # CIFAR 10 doesn't use gaussian blur\n",
        "            transforms.RandomResizedCrop(size=32,scale=(0.08,0.1),ratio=(0.75,1.33)),\n",
        "            transforms.ToTensor(),\n",
        "            # the normalize numbers are from previous assignment\n",
        "            # transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
        "            ])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cxUPRNVOYQ-M",
        "outputId": "515ebcdb-536f-47b3-a6be-7562ed7eef90"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Sequential(\n",
              "  (0): ResNet18(\n",
              "    (conv1): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (conv1_bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (layer1): Sequential(\n",
              "      (0): Block(\n",
              "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        (conv1_bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        (conv2_bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (identity): Sequential()\n",
              "      )\n",
              "      (1): Block(\n",
              "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        (conv1_bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        (conv2_bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (identity): Sequential()\n",
              "      )\n",
              "    )\n",
              "    (layer2): Sequential(\n",
              "      (0): Block(\n",
              "        (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
              "        (conv1_bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        (conv2_bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (identity): Sequential(\n",
              "          (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2))\n",
              "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "      )\n",
              "      (1): Block(\n",
              "        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        (conv1_bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        (conv2_bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (identity): Sequential()\n",
              "      )\n",
              "    )\n",
              "    (layer3): Sequential(\n",
              "      (0): Block(\n",
              "        (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
              "        (conv1_bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        (conv2_bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (identity): Sequential(\n",
              "          (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2))\n",
              "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "      )\n",
              "      (1): Block(\n",
              "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        (conv1_bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        (conv2_bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (identity): Sequential()\n",
              "      )\n",
              "    )\n",
              "    (layer4): Sequential(\n",
              "      (0): Block(\n",
              "        (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
              "        (conv1_bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        (conv2_bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (identity): Sequential(\n",
              "          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2))\n",
              "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "      )\n",
              "      (1): Block(\n",
              "        (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        (conv1_bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        (conv2_bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (identity): Sequential()\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (1): MLP(\n",
              "    (mlp): Sequential(\n",
              "      (0): Linear(in_features=512, out_features=512, bias=True)\n",
              "      (1): ReLU()\n",
              "      (2): Linear(in_features=512, out_features=128, bias=True)\n",
              "    )\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "net_f = ResNet18(3, Block)\n",
        "net_g = MLP(512)\n",
        "net = nn.Sequential(net_f, net_g)\n",
        "optimizer = optim.Adam(net.parameters(), lr=0.0003*(BATCH_SIZE / 256), weight_decay=1e-4)\n",
        "# optimizer = optim.SGD(net.parameters(), lr=0.3*(BATCH_SIZE / 256), weight_decay=1e-6)\n",
        "# optimizer = optim.SGD(net.parameters(), lr=LR, weight_decay=1e-6)\n",
        "# scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=150, gamma=0.1)\n",
        "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=len(trainset))\n",
        "net.to(device)\n",
        "net.train()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bqhu4T1BY5Td"
      },
      "outputs": [],
      "source": [
        "def compute_loss(yhat, t):\n",
        "    \"\"\"\n",
        "    Computing the contrastive loss based on cosine similarity\n",
        "    input:\n",
        "        yhat: [tensor] latent embedding features size: BATCH_SIZE * 128\n",
        "        t: [float] temperature range: (0.0, 1.0)\n",
        "    output:\n",
        "        loss: [tensor] 1D\n",
        "    \"\"\"\n",
        "    \n",
        "    # testing code\n",
        "    #from collections import defaultdict\n",
        "    #cache = defaultdict(int)\n",
        "    #for i in range(yhat.shape[0]):\n",
        "    #    for j in range(i+1, yhat.shape[0]):\n",
        "    #        val = torch.nn.functional.cosine_similarity(yhat[i], yhat[j], dim=0, eps=1e-8)\n",
        "    #        cache[(i, j)] = val\n",
        "    #        cache[(j, i)] = val\n",
        "    \n",
        "    N = yhat.shape[0]\n",
        "\n",
        "    # Calculate the pair-wise consine similarity\n",
        "    cache = torch.nn.functional.cosine_similarity(yhat.unsqueeze(0), yhat.unsqueeze(1), dim=-1, eps=1e-8)\n",
        "    cache = cache / t\n",
        "    \n",
        "    # Delete the diagonal entries\n",
        "    mask = torch.eye(N, dtype=bool)\n",
        "    cache = cache[~mask].view((N, N-1))\n",
        "\n",
        "    # Make pesudo-labels\n",
        "    label = []\n",
        "    for i in range(N // 2):\n",
        "        label.append(int(2 *i))\n",
        "        label.append(int(2 *i))\n",
        "    label = torch.tensor(label)\n",
        "    label = label.to(device)\n",
        "\n",
        "    # Calculate the cross entropy loss\n",
        "    loss = F.cross_entropy(cache, label)\n",
        "\n",
        "    return loss\n",
        "    \n",
        "\n",
        "    \"\"\"\n",
        "    # Calculate the pair-wise consine similarity\n",
        "    cache = torch.nn.functional.cosine_similarity(yhat.unsqueeze(0), yhat.unsqueeze(1), dim=-1, eps=1e-8)\n",
        "    # print(cache)\n",
        "    cache = torch.exp(cache / t)\n",
        "    cache_sum = torch.sum(cache, dim=1)\n",
        "\n",
        "    \n",
        "    # Compute the contrastive loss\n",
        "    loss = 0\n",
        "    for n in range(yhat.shape[0]):\n",
        "        # Get the index of positive pairs, based on 2 tensors of the same pair are adjacent in terms of index\n",
        "        i = n\n",
        "        if i % 2 == 0:\n",
        "            j = i + 1\n",
        "        else:\n",
        "            j = i - 1\n",
        "\n",
        "        # The numerator is between the positive pair\n",
        "        # The denominator is between one tensor with all OTHER tensors\n",
        "        numerator = cache[i, j]\n",
        "        denominator = cache_sum[i] - cache[i, i]\n",
        "        #denominator = 0\n",
        "        #for k in range(yhat.shape[0]):\n",
        "        #    if k != i:\n",
        "        #        denominator += cache[i, k]\n",
        "        cur_loss = (-1) * torch.log(numerator / denominator)\n",
        "        # Add up the loss and take the average\n",
        "        loss += (1 / (2 * yhat.shape[0])) * cur_loss\n",
        "    loss = torch.tensor(loss.item())\n",
        "    loss.requires_grad = True\n",
        "    # loss = torch.mean(loss)\n",
        "    \n",
        "    return loss\n",
        "    \"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mir0ML6bQ2Jy",
        "outputId": "f81ce0ab-5e1d-47de-9b69-700c5ea85912"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 0, Average Contrastive Loss 5.820658\n",
            "Epoch: 1, Average Contrastive Loss 5.721632\n",
            "Epoch: 2, Average Contrastive Loss 5.594156\n",
            "Epoch: 3, Average Contrastive Loss 5.509527\n",
            "Epoch: 4, Average Contrastive Loss 5.414582\n",
            "Epoch: 5, Average Contrastive Loss 5.338105\n",
            "Epoch: 6, Average Contrastive Loss 5.274501\n",
            "Epoch: 7, Average Contrastive Loss 5.203047\n",
            "Epoch: 8, Average Contrastive Loss 5.160844\n",
            "Epoch: 9, Average Contrastive Loss 5.092528\n",
            "Epoch: 10, Average Contrastive Loss 5.058919\n",
            "Epoch: 11, Average Contrastive Loss 4.985517\n",
            "Epoch: 12, Average Contrastive Loss 4.946435\n",
            "Epoch: 13, Average Contrastive Loss 4.875840\n",
            "Epoch: 14, Average Contrastive Loss 4.859717\n",
            "Epoch: 15, Average Contrastive Loss 4.802228\n",
            "Epoch: 16, Average Contrastive Loss 4.776885\n",
            "Epoch: 17, Average Contrastive Loss 4.703448\n",
            "Epoch: 18, Average Contrastive Loss 4.699400\n",
            "Epoch: 19, Average Contrastive Loss 4.628539\n",
            "Epoch: 20, Average Contrastive Loss 4.624438\n",
            "Epoch: 21, Average Contrastive Loss 4.580088\n",
            "Epoch: 22, Average Contrastive Loss 4.585888\n",
            "Epoch: 23, Average Contrastive Loss 4.515331\n",
            "Epoch: 24, Average Contrastive Loss 4.529028\n",
            "Epoch: 25, Average Contrastive Loss 4.472161\n",
            "Epoch: 26, Average Contrastive Loss 4.500422\n",
            "Epoch: 27, Average Contrastive Loss 4.434369\n",
            "Epoch: 28, Average Contrastive Loss 4.450937\n",
            "Epoch: 29, Average Contrastive Loss 4.391416\n",
            "Epoch: 30, Average Contrastive Loss 4.409222\n",
            "Epoch: 31, Average Contrastive Loss 4.354031\n",
            "Epoch: 32, Average Contrastive Loss 4.366389\n",
            "Epoch: 33, Average Contrastive Loss 4.323465\n",
            "Epoch: 34, Average Contrastive Loss 4.353478\n",
            "Epoch: 35, Average Contrastive Loss 4.289315\n",
            "Epoch: 36, Average Contrastive Loss 4.305373\n",
            "Epoch: 37, Average Contrastive Loss 4.262760\n",
            "Epoch: 38, Average Contrastive Loss 4.278751\n",
            "Epoch: 39, Average Contrastive Loss 4.229466\n",
            "Epoch: 40, Average Contrastive Loss 4.272970\n",
            "Epoch: 41, Average Contrastive Loss 4.211793\n",
            "Epoch: 42, Average Contrastive Loss 4.220667\n",
            "Epoch: 43, Average Contrastive Loss 4.192276\n",
            "Epoch: 44, Average Contrastive Loss 4.198292\n",
            "Epoch: 45, Average Contrastive Loss 4.161105\n",
            "Epoch: 46, Average Contrastive Loss 4.187468\n",
            "Epoch: 47, Average Contrastive Loss 4.127982\n",
            "Epoch: 48, Average Contrastive Loss 4.173739\n",
            "Epoch: 49, Average Contrastive Loss 4.107521\n",
            "Epoch: 50, Average Contrastive Loss 4.149846\n",
            "Epoch: 51, Average Contrastive Loss 4.096089\n",
            "Epoch: 52, Average Contrastive Loss 4.123489\n",
            "Epoch: 53, Average Contrastive Loss 4.078519\n",
            "Epoch: 54, Average Contrastive Loss 4.102828\n",
            "Epoch: 55, Average Contrastive Loss 4.052250\n",
            "Epoch: 56, Average Contrastive Loss 4.089257\n",
            "Epoch: 57, Average Contrastive Loss 4.015493\n",
            "Epoch: 58, Average Contrastive Loss 4.066499\n",
            "Epoch: 59, Average Contrastive Loss 4.015911\n",
            "Epoch: 60, Average Contrastive Loss 4.033879\n",
            "Epoch: 61, Average Contrastive Loss 4.018434\n",
            "Epoch: 62, Average Contrastive Loss 4.029393\n",
            "Epoch: 63, Average Contrastive Loss 3.977865\n",
            "Epoch: 64, Average Contrastive Loss 4.029171\n",
            "Epoch: 65, Average Contrastive Loss 3.970775\n",
            "Epoch: 66, Average Contrastive Loss 4.001952\n",
            "Epoch: 67, Average Contrastive Loss 3.959701\n",
            "Epoch: 68, Average Contrastive Loss 3.986511\n",
            "Epoch: 69, Average Contrastive Loss 3.931819\n",
            "Epoch: 70, Average Contrastive Loss 3.972668\n",
            "Epoch: 71, Average Contrastive Loss 3.920619\n",
            "Epoch: 72, Average Contrastive Loss 3.959499\n",
            "Epoch: 73, Average Contrastive Loss 3.913196\n",
            "Epoch: 74, Average Contrastive Loss 3.946448\n",
            "Epoch: 75, Average Contrastive Loss 3.900311\n",
            "Epoch: 76, Average Contrastive Loss 3.947068\n",
            "Epoch: 77, Average Contrastive Loss 3.867847\n",
            "Epoch: 78, Average Contrastive Loss 3.925869\n",
            "Epoch: 79, Average Contrastive Loss 3.870904\n",
            "Epoch: 80, Average Contrastive Loss 3.907010\n",
            "Epoch: 81, Average Contrastive Loss 3.863589\n",
            "Epoch: 82, Average Contrastive Loss 3.895761\n",
            "Epoch: 83, Average Contrastive Loss 3.845341\n",
            "Epoch: 84, Average Contrastive Loss 3.881304\n",
            "Epoch: 85, Average Contrastive Loss 3.847315\n",
            "Epoch: 86, Average Contrastive Loss 3.890598\n",
            "Epoch: 87, Average Contrastive Loss 3.817345\n",
            "Epoch: 88, Average Contrastive Loss 3.866219\n",
            "Epoch: 89, Average Contrastive Loss 3.837506\n",
            "Epoch: 90, Average Contrastive Loss 3.845436\n",
            "Epoch: 91, Average Contrastive Loss 3.819063\n",
            "Epoch: 92, Average Contrastive Loss 3.830633\n",
            "Epoch: 93, Average Contrastive Loss 3.787161\n",
            "Epoch: 94, Average Contrastive Loss 3.830997\n",
            "Epoch: 95, Average Contrastive Loss 3.775239\n",
            "Epoch: 96, Average Contrastive Loss 3.833764\n",
            "Epoch: 97, Average Contrastive Loss 3.773633\n",
            "Epoch: 98, Average Contrastive Loss 3.818766\n",
            "Epoch: 99, Average Contrastive Loss 3.770106\n",
            "Epoch: 100, Average Contrastive Loss 3.805448\n",
            "Epoch: 101, Average Contrastive Loss 3.742406\n",
            "Epoch: 102, Average Contrastive Loss 3.794010\n",
            "Epoch: 103, Average Contrastive Loss 3.756870\n",
            "Epoch: 104, Average Contrastive Loss 3.778848\n",
            "Epoch: 105, Average Contrastive Loss 3.742079\n",
            "Epoch: 106, Average Contrastive Loss 3.795229\n",
            "Epoch: 107, Average Contrastive Loss 3.730182\n",
            "Epoch: 108, Average Contrastive Loss 3.773451\n",
            "Epoch: 109, Average Contrastive Loss 3.720519\n",
            "Epoch: 110, Average Contrastive Loss 3.754388\n",
            "Epoch: 111, Average Contrastive Loss 3.700742\n",
            "Epoch: 112, Average Contrastive Loss 3.764133\n",
            "Epoch: 113, Average Contrastive Loss 3.700468\n",
            "Epoch: 114, Average Contrastive Loss 3.758238\n",
            "Epoch: 115, Average Contrastive Loss 3.708716\n",
            "Epoch: 116, Average Contrastive Loss 3.749332\n",
            "Epoch: 117, Average Contrastive Loss 3.709327\n",
            "Epoch: 118, Average Contrastive Loss 3.739836\n",
            "Epoch: 119, Average Contrastive Loss 3.690491\n",
            "Epoch: 120, Average Contrastive Loss 3.729268\n",
            "Epoch: 121, Average Contrastive Loss 3.665871\n",
            "Epoch: 122, Average Contrastive Loss 3.716053\n",
            "Epoch: 123, Average Contrastive Loss 3.681180\n",
            "Epoch: 124, Average Contrastive Loss 3.708963\n",
            "Epoch: 125, Average Contrastive Loss 3.674304\n",
            "Epoch: 126, Average Contrastive Loss 3.708729\n",
            "Epoch: 127, Average Contrastive Loss 3.659298\n",
            "Epoch: 128, Average Contrastive Loss 3.699797\n",
            "Epoch: 129, Average Contrastive Loss 3.643050\n",
            "Epoch: 130, Average Contrastive Loss 3.679896\n",
            "Epoch: 131, Average Contrastive Loss 3.647709\n",
            "Epoch: 132, Average Contrastive Loss 3.680846\n",
            "Epoch: 133, Average Contrastive Loss 3.642367\n",
            "Epoch: 134, Average Contrastive Loss 3.668106\n",
            "Epoch: 135, Average Contrastive Loss 3.635663\n",
            "Epoch: 136, Average Contrastive Loss 3.661178\n",
            "Epoch: 137, Average Contrastive Loss 3.617096\n",
            "Epoch: 138, Average Contrastive Loss 3.659807\n",
            "Epoch: 139, Average Contrastive Loss 3.618751\n",
            "Epoch: 140, Average Contrastive Loss 3.666503\n",
            "Epoch: 141, Average Contrastive Loss 3.594800\n",
            "Epoch: 142, Average Contrastive Loss 3.622087\n",
            "Epoch: 143, Average Contrastive Loss 3.603739\n",
            "Epoch: 144, Average Contrastive Loss 3.624389\n",
            "Epoch: 145, Average Contrastive Loss 3.590760\n",
            "Epoch: 146, Average Contrastive Loss 3.620325\n",
            "Epoch: 147, Average Contrastive Loss 3.565373\n",
            "Epoch: 148, Average Contrastive Loss 3.622690\n",
            "Epoch: 149, Average Contrastive Loss 3.560929\n",
            "Epoch: 150, Average Contrastive Loss 3.618102\n",
            "Epoch: 151, Average Contrastive Loss 3.568707\n",
            "Epoch: 152, Average Contrastive Loss 3.610115\n",
            "Epoch: 153, Average Contrastive Loss 3.573815\n",
            "Epoch: 154, Average Contrastive Loss 3.607946\n",
            "Epoch: 155, Average Contrastive Loss 3.536155\n",
            "Epoch: 156, Average Contrastive Loss 3.602390\n",
            "Epoch: 157, Average Contrastive Loss 3.542975\n",
            "Epoch: 158, Average Contrastive Loss 3.602602\n",
            "Epoch: 159, Average Contrastive Loss 3.530923\n",
            "Epoch: 160, Average Contrastive Loss 3.607742\n",
            "Epoch: 161, Average Contrastive Loss 3.540169\n",
            "Epoch: 162, Average Contrastive Loss 3.567815\n",
            "Epoch: 163, Average Contrastive Loss 3.522286\n",
            "Epoch: 164, Average Contrastive Loss 3.594029\n",
            "Epoch: 165, Average Contrastive Loss 3.517470\n",
            "Epoch: 166, Average Contrastive Loss 3.546606\n",
            "Epoch: 167, Average Contrastive Loss 3.522263\n",
            "Epoch: 168, Average Contrastive Loss 3.556696\n",
            "Epoch: 169, Average Contrastive Loss 3.508203\n",
            "Epoch: 170, Average Contrastive Loss 3.544764\n",
            "Epoch: 171, Average Contrastive Loss 3.509337\n",
            "Epoch: 172, Average Contrastive Loss 3.534325\n",
            "Epoch: 173, Average Contrastive Loss 3.501904\n",
            "Epoch: 174, Average Contrastive Loss 3.535424\n",
            "Epoch: 175, Average Contrastive Loss 3.518466\n",
            "Epoch: 176, Average Contrastive Loss 3.544827\n",
            "Epoch: 177, Average Contrastive Loss 3.490257\n",
            "Epoch: 178, Average Contrastive Loss 3.533569\n",
            "Epoch: 179, Average Contrastive Loss 3.479598\n",
            "Epoch: 180, Average Contrastive Loss 3.548464\n",
            "Epoch: 181, Average Contrastive Loss 3.481295\n",
            "Epoch: 182, Average Contrastive Loss 3.529750\n",
            "Epoch: 183, Average Contrastive Loss 3.476383\n",
            "Epoch: 184, Average Contrastive Loss 3.512063\n",
            "Epoch: 185, Average Contrastive Loss 3.461645\n",
            "Epoch: 186, Average Contrastive Loss 3.504699\n",
            "Epoch: 187, Average Contrastive Loss 3.452891\n",
            "Epoch: 188, Average Contrastive Loss 3.518337\n",
            "Epoch: 189, Average Contrastive Loss 3.462694\n",
            "Epoch: 190, Average Contrastive Loss 3.498677\n",
            "Epoch: 191, Average Contrastive Loss 3.456943\n",
            "Epoch: 192, Average Contrastive Loss 3.473069\n",
            "Epoch: 193, Average Contrastive Loss 3.447028\n",
            "Epoch: 194, Average Contrastive Loss 3.493658\n",
            "Epoch: 195, Average Contrastive Loss 3.444570\n",
            "Epoch: 196, Average Contrastive Loss 3.496441\n",
            "Epoch: 197, Average Contrastive Loss 3.434641\n",
            "Epoch: 198, Average Contrastive Loss 3.487180\n",
            "Epoch: 199, Average Contrastive Loss 3.429700\n"
          ]
        }
      ],
      "source": [
        "# loop through each batch in trainset \n",
        "LOSSES = []\n",
        "EPOCHS = 200\n",
        "OPTIM_LOSS = float('inf')\n",
        "\n",
        "for epoch in range(EPOCHS):\n",
        "    cost = 0\n",
        "    for data, label in trainset:\n",
        "        for ind_img in range(len(data)): # loop through each image in batch \n",
        "            par_tensor = data[ind_img]\n",
        "            cur_tensor_0 = train_transform(par_tensor) # first aug\n",
        "            cur_tensor_1 = train_transform(par_tensor) # second aug \n",
        "            # resize \n",
        "            cur_tensor_0, cur_tensor_1 = torch.unsqueeze(cur_tensor_0, 0), torch.unsqueeze(cur_tensor_1, 0) \n",
        "            # if this is the first image in the batch, we just concat the 2 data aug \n",
        "            if ind_img == 0:\n",
        "                total_tensor = torch.cat((cur_tensor_0, cur_tensor_1), dim=0)\n",
        "            # else append to the previous augmented pair in the batch \n",
        "            else:\n",
        "                total_tensor = torch.cat((total_tensor, cur_tensor_0, cur_tensor_1), dim=0)\n",
        "            \n",
        "        total_tensor = total_tensor.to(device)\n",
        "        # pass <total_tensor> into the model \n",
        "        yhat = net(total_tensor)\n",
        "        # calculate loss \n",
        "        # loss = compute_loss(yhat, 0.5)\n",
        "        loss = compute_loss(yhat, 0.07)\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        scheduler.step()\n",
        "        cost += loss.item()\n",
        "\n",
        "    avg_loss = cost / len(trainset)\n",
        "    LOSSES.append(avg_loss)\n",
        "    if avg_loss < OPTIM_LOSS:\n",
        "        OPTIM_LOSS = avg_loss\n",
        "        torch.save(net.state_dict(), 'simclr.pt')\n",
        "        torch.save(net_f.state_dict(), 'simclr_netf.pt')\n",
        "    print(\"Epoch: {}, Average Contrastive Loss {:f}\".format(epoch, avg_loss))\n",
        "        "
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot([_ for _ in range(len(LOSSES))], LOSSES)"
      ],
      "metadata": {
        "id": "BsC8tqlyv_-i",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        },
        "outputId": "275443aa-2845-427d-bf8d-d46c2110925d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7f3e24519f40>]"
            ]
          },
          "metadata": {},
          "execution_count": 8
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(LOSSES)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jFMbcf7iMpQE",
        "outputId": "af0a83ff-237d-4f28-fc17-e82412af7fde"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[5.820658277492134, 5.721632327352252, 5.594156133885286, 5.509526573881811, 5.414581688082948, 5.338105442572613, 5.274500557354519, 5.203046572451689, 5.160844401437409, 5.092527671736114, 5.058918698709839, 4.985517338830597, 4.946435492865893, 4.875840437655547, 4.85971705645931, 4.802227599280221, 4.776885053332971, 4.70344833938443, 4.6994004869947625, 4.628538919954884, 4.624437997535783, 4.580087858803418, 4.585887542792729, 4.515331382654151, 4.529028286739272, 4.472160650759327, 4.5004222368707465, 4.434369194264314, 4.450937279633114, 4.391415692105586, 4.409221734319415, 4.354030645623499, 4.366388724774731, 4.323465159961155, 4.353477543714095, 4.289314992573797, 4.305372899892379, 4.262760090584657, 4.278750838065634, 4.2294658154857405, 4.272970109569783, 4.2117926441893285, 4.220666612897601, 4.19227632089537, 4.198292414752805, 4.1611045781446965, 4.187467697931796, 4.127982486267479, 4.173739203384945, 4.107520794381901, 4.149846331197388, 4.0960886137826105, 4.123488704768979, 4.0785190669857725, 4.102828286132034, 4.052249884118839, 4.089256870503328, 4.015492855286111, 4.066499430306104, 4.015911233668425, 4.0338786609318795, 4.018434335990828, 4.029393158396896, 3.977865423474993, 4.029170524100868, 3.970775094567513, 4.00195154243586, 3.959700674426799, 3.986511297371923, 3.9318192163292243, 3.972668461653651, 3.920619009708872, 3.9594985356136245, 3.9131957414198895, 3.946448480596348, 3.9003114128599363, 3.947067772855564, 3.8678470995961405, 3.925868517282058, 3.8709042753492082, 3.907010237781369, 3.8635887467131322, 3.8957610762849146, 3.8453405049382425, 3.881303509887384, 3.8473147056540666, 3.8905981110066783, 3.817344972065517, 3.8662194597477817, 3.8375056373829746, 3.845435834660822, 3.8190630868989595, 3.8306325503758023, 3.787160968293949, 3.830996717725481, 3.7752385638198076, 3.8337644946818448, 3.7736328013089238, 3.8187662022454396, 3.7701056490139084, 3.805448356939822, 3.7424056286714515, 3.7940103922571455, 3.756869704139476, 3.778848357346593, 3.742078601097574, 3.79522905666001, 3.730182009083884, 3.773451166493552, 3.7205189624611212, 3.7543880988140494, 3.7007419065553315, 3.764132623769799, 3.7004675402933236, 3.758238253544788, 3.7087155823804894, 3.7493322722765865, 3.7093273960814184, 3.73983612352488, 3.6904913478968093, 3.729267936580035, 3.665870805175937, 3.7160532620488382, 3.6811795319829668, 3.708963382000826, 3.6743044622090397, 3.708728707566553, 3.6592979297346, 3.6997968104420877, 3.643049702352407, 3.67989581823349, 3.64770879550856, 3.6808456012180875, 3.6423672620131047, 3.668106031661131, 3.6356629607628803, 3.6611782032616285, 3.6170961114825033, 3.659806569011844, 3.6187511451390324, 3.6665029258144144, 3.5947998190412718, 3.622087138039725, 3.603738912514278, 3.6243889112861787, 3.5907597858078626, 3.6203247211417375, 3.5653726361235796, 3.622690424627187, 3.5609287899367663, 3.6181019933856264, 3.5687066231455122, 3.6101151960236684, 3.5738150745022055, 3.6079456550734386, 3.5361546837553686, 3.6023900594030107, 3.5429747262779547, 3.602601704548816, 3.5309232862628237, 3.607742168465439, 3.5401689556180216, 3.567815463761894, 3.522285596448548, 3.5940292915519403, 3.517469947435418, 3.5466056867521636, 3.5222627362426446, 3.5566958687743364, 3.5082034286187618, 3.544763630750228, 3.5093371199101817, 3.534325214064851, 3.5019036592269432, 3.5354243516921997, 3.5184656405935484, 3.544827432048564, 3.4902572656164366, 3.533568652308717, 3.479598177939045, 3.5484640099564375, 3.4812954518259787, 3.529750146427933, 3.476382813891586, 3.512062750300583, 3.461644772364169, 3.5046985903564765, 3.45289148724809, 3.518336608701823, 3.4626939041273936, 3.4986771892528146, 3.45694270182629, 3.473069327218192, 3.447027926542321, 3.493658112019909, 3.444569764088611, 3.4964414263258177, 3.4346407432945405, 3.4871804580396537, 3.429700086311418]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"{} epochs in total.\".format(len(LOSSES)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cZnTikYopdoq",
        "outputId": "b881a6e0-a7d2-455f-8ca4-7739241bdbed"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "200 epochs in total.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(net.state_dict(), 'simclr_last_epoch.pt')\n",
        "torch.save(net_f.state_dict(), 'simclr_netf_last_epoch.pt')"
      ],
      "metadata": {
        "id": "IQHaf8n3ptN5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7VoxTNVH0zLL"
      },
      "outputs": [],
      "source": [
        "# decide the learning rate, whether to implement lr decay\n",
        "# linear eval (discard net_g, connect net_f with logistic regressor, freeze net_f, train the whole net)\n",
        "# supervised counterpart, for simCLR epoch=90\n",
        "# write the report"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Linear Evaluation"
      ],
      "metadata": {
        "id": "xnNpaNBjNqy1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class LogisticRegression(nn.Module):\n",
        "    def __init__(self, in_c):\n",
        "      super(LogisticRegression, self).__init__()\n",
        "      \n",
        "      self.linear = nn.Linear(in_c, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "      out = x.view(x.size(0), -1)\n",
        "      out = self.linear(out)\n",
        "      # out = F.softmax(out, dim=1)\n",
        "      return out"
      ],
      "metadata": {
        "id": "YZMrCAKzNxz2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "net_f = ResNet18(3, Block)\n",
        "# net_f.load_state_dict(torch.load(\"simclr_netf_last_epoch.pt\"))\n",
        "net_g = MLP(512)\n",
        "net = nn.Sequential(net_f, net_g)\n",
        "net.load_state_dict(torch.load(\"simclr_last_epoch.pt\"))\n",
        "net_f.eval()\n",
        "for parameter in net_f.parameters():\n",
        "    parameter.requires_grad = False\n",
        "\n",
        "lr = LogisticRegression(512)\n",
        "lr.train()\n",
        "\n",
        "net_eval = nn.Sequential(net_f, lr)"
      ],
      "metadata": {
        "id": "MF7EqU7UOmP4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "BATCH_SIZE = 256\n",
        "\n",
        "optimizer = optim.Adam(net_eval.parameters(), lr=0.001*(BATCH_SIZE / 256), weight_decay=1e-4)\n",
        "net_eval.to(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yIDKnFxTPPWe",
        "outputId": "e4d7e345-c921-498e-ae89-35cfb3ca9929"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Sequential(\n",
              "  (0): ResNet18(\n",
              "    (conv1): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (conv1_bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (layer1): Sequential(\n",
              "      (0): Block(\n",
              "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        (conv1_bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        (conv2_bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (identity): Sequential()\n",
              "      )\n",
              "      (1): Block(\n",
              "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        (conv1_bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        (conv2_bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (identity): Sequential()\n",
              "      )\n",
              "    )\n",
              "    (layer2): Sequential(\n",
              "      (0): Block(\n",
              "        (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
              "        (conv1_bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        (conv2_bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (identity): Sequential(\n",
              "          (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2))\n",
              "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "      )\n",
              "      (1): Block(\n",
              "        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        (conv1_bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        (conv2_bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (identity): Sequential()\n",
              "      )\n",
              "    )\n",
              "    (layer3): Sequential(\n",
              "      (0): Block(\n",
              "        (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
              "        (conv1_bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        (conv2_bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (identity): Sequential(\n",
              "          (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2))\n",
              "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "      )\n",
              "      (1): Block(\n",
              "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        (conv1_bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        (conv2_bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (identity): Sequential()\n",
              "      )\n",
              "    )\n",
              "    (layer4): Sequential(\n",
              "      (0): Block(\n",
              "        (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
              "        (conv1_bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        (conv2_bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (identity): Sequential(\n",
              "          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2))\n",
              "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "      )\n",
              "      (1): Block(\n",
              "        (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        (conv1_bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        (conv2_bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (identity): Sequential()\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (1): LogisticRegression(\n",
              "    (linear): Linear(in_features=512, out_features=10, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "trainset = torch.utils.data.DataLoader(\n",
        "    datasets.CIFAR10('./data', train=True, download=True, transform=linear_eval_transform),\n",
        "    batch_size = BATCH_SIZE, shuffle=True, )\n",
        "\n",
        "testset = torch.utils.data.DataLoader(\n",
        "    datasets.CIFAR10('./data', train=False, download=True, transform=linear_eval_transform_test),\n",
        "    batch_size = BATCH_SIZE, shuffle=True, )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Op51VbMkWLfA",
        "outputId": "40530e93-eb82-4738-b1a1-9b15e04c03e2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# loop through each batch in trainset \n",
        "LOSSES_TRAIN, LOSSES_EVAL = [], []\n",
        "TEST_ACC = []\n",
        "EPOCHS = 30\n",
        "OPTIM_LOSS = float('inf')\n",
        "\n",
        "for epoch in range(EPOCHS):\n",
        "    cost = 0\n",
        "    lr.train()\n",
        "    for data, label in trainset:\n",
        "        data, label = data.to(device), label.to(device)\n",
        "        yhat = net_eval(data)\n",
        "        # calculate loss \n",
        "        loss = F.cross_entropy(yhat, label)\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        # scheduler.step()\n",
        "        cost += loss.item()\n",
        "\n",
        "    avg_loss_train = cost / len(trainset)\n",
        "    LOSSES_TRAIN.append(avg_loss_train)\n",
        "\n",
        "    lr.eval()\n",
        "    total, correct = 0, 0\n",
        "    with torch.no_grad():\n",
        "        for data, label in testset:\n",
        "            data, label = data.to(device), label.to(device)\n",
        "            y_pred = net_eval(data)\n",
        "            # calculate loss \n",
        "            loss = F.cross_entropy(y_pred, label)\n",
        "            cost += loss.item()\n",
        "\n",
        "            total += len(label)\n",
        "            y_hat = torch.argmax(y_pred, dim=1)\n",
        "            correct += torch.sum(torch.eq(y_hat, label)).item()\n",
        "\n",
        "    avg_loss_test = cost / len(testset)\n",
        "    LOSSES_EVAL.append(avg_loss_test)\n",
        "\n",
        "    test_accuracy = correct / total\n",
        "    TEST_ACC.append(test_accuracy)\n",
        "\n",
        "    print(\"Epoch: {}; TRAIN LOSS: {:f}; TEST LOSS: {:f}; TEST ACC: {:f}\".format(epoch, avg_loss_train, avg_loss_test, test_accuracy))\n",
        "    "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hUTzBp2TQoW6",
        "outputId": "9ccd0b87-fafa-4b30-9fd3-010513313a26"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 0; TRAIN LOSS: 2.105921; TEST LOSS: 12.327968; TEST ACC: 0.491100\n",
            "Epoch: 1; TRAIN LOSS: 2.017360; TEST LOSS: 11.860382; TEST ACC: 0.506100\n",
            "Epoch: 2; TRAIN LOSS: 1.999504; TEST LOSS: 11.766348; TEST ACC: 0.502600\n",
            "Epoch: 3; TRAIN LOSS: 1.990215; TEST LOSS: 11.710349; TEST ACC: 0.511100\n",
            "Epoch: 4; TRAIN LOSS: 1.980991; TEST LOSS: 11.663511; TEST ACC: 0.513000\n",
            "Epoch: 5; TRAIN LOSS: 1.982077; TEST LOSS: 11.659925; TEST ACC: 0.522700\n",
            "Epoch: 6; TRAIN LOSS: 1.975038; TEST LOSS: 11.623510; TEST ACC: 0.523900\n",
            "Epoch: 7; TRAIN LOSS: 1.972501; TEST LOSS: 11.608567; TEST ACC: 0.521300\n",
            "Epoch: 8; TRAIN LOSS: 1.969676; TEST LOSS: 11.589677; TEST ACC: 0.526000\n",
            "Epoch: 9; TRAIN LOSS: 1.972474; TEST LOSS: 11.602391; TEST ACC: 0.532700\n",
            "Epoch: 10; TRAIN LOSS: 1.969390; TEST LOSS: 11.594925; TEST ACC: 0.520900\n",
            "Epoch: 11; TRAIN LOSS: 1.965879; TEST LOSS: 11.571742; TEST ACC: 0.527300\n",
            "Epoch: 12; TRAIN LOSS: 1.964479; TEST LOSS: 11.551940; TEST ACC: 0.540200\n",
            "Epoch: 13; TRAIN LOSS: 1.967188; TEST LOSS: 11.577784; TEST ACC: 0.525900\n",
            "Epoch: 14; TRAIN LOSS: 1.965451; TEST LOSS: 11.572351; TEST ACC: 0.521600\n",
            "Epoch: 15; TRAIN LOSS: 1.964122; TEST LOSS: 11.560242; TEST ACC: 0.529600\n",
            "Epoch: 16; TRAIN LOSS: 1.962829; TEST LOSS: 11.556033; TEST ACC: 0.525500\n",
            "Epoch: 17; TRAIN LOSS: 1.963000; TEST LOSS: 11.550814; TEST ACC: 0.525900\n",
            "Epoch: 18; TRAIN LOSS: 1.961962; TEST LOSS: 11.542231; TEST ACC: 0.533800\n",
            "Epoch: 19; TRAIN LOSS: 1.961183; TEST LOSS: 11.540523; TEST ACC: 0.527500\n",
            "Epoch: 20; TRAIN LOSS: 1.961404; TEST LOSS: 11.542421; TEST ACC: 0.530500\n",
            "Epoch: 21; TRAIN LOSS: 1.963080; TEST LOSS: 11.550837; TEST ACC: 0.532200\n",
            "Epoch: 22; TRAIN LOSS: 1.960030; TEST LOSS: 11.529456; TEST ACC: 0.537100\n",
            "Epoch: 23; TRAIN LOSS: 1.960713; TEST LOSS: 11.542357; TEST ACC: 0.529000\n",
            "Epoch: 24; TRAIN LOSS: 1.959562; TEST LOSS: 11.530400; TEST ACC: 0.535300\n",
            "Epoch: 25; TRAIN LOSS: 1.958828; TEST LOSS: 11.527025; TEST ACC: 0.535000\n",
            "Epoch: 26; TRAIN LOSS: 1.961792; TEST LOSS: 11.541171; TEST ACC: 0.527600\n",
            "Epoch: 27; TRAIN LOSS: 1.957810; TEST LOSS: 11.518385; TEST ACC: 0.535800\n",
            "Epoch: 28; TRAIN LOSS: 1.959795; TEST LOSS: 11.532567; TEST ACC: 0.534700\n",
            "Epoch: 29; TRAIN LOSS: 1.959248; TEST LOSS: 11.533354; TEST ACC: 0.531000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# try without softmax layer\n",
        "# loop through each batch in trainset \n",
        "LOSSES_TRAIN, LOSSES_EVAL = [], []\n",
        "TEST_ACC = []\n",
        "EPOCHS = 30\n",
        "OPTIM_LOSS = float('inf')\n",
        "\n",
        "for epoch in range(EPOCHS):\n",
        "    cost = 0\n",
        "    lr.train()\n",
        "    for data, label in trainset:\n",
        "        data, label = data.to(device), label.to(device)\n",
        "        yhat = net_eval(data)\n",
        "        # calculate loss \n",
        "        loss = F.cross_entropy(yhat, label)\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        # scheduler.step()\n",
        "        cost += loss.item()\n",
        "\n",
        "    avg_loss_train = cost / len(trainset)\n",
        "    LOSSES_TRAIN.append(avg_loss_train)\n",
        "\n",
        "    lr.eval()\n",
        "    total, correct = 0, 0\n",
        "    with torch.no_grad():\n",
        "        for data, label in testset:\n",
        "            data, label = data.to(device), label.to(device)\n",
        "            y_pred = net_eval(data)\n",
        "            # calculate loss \n",
        "            loss = F.cross_entropy(y_pred, label)\n",
        "            cost += loss.item()\n",
        "\n",
        "            total += len(label)\n",
        "            y_hat = torch.argmax(y_pred, dim=1)\n",
        "            correct += torch.sum(torch.eq(y_hat, label)).item()\n",
        "\n",
        "    avg_loss_test = cost / len(testset)\n",
        "    LOSSES_EVAL.append(avg_loss_test)\n",
        "\n",
        "    test_accuracy = correct / total\n",
        "    TEST_ACC.append(test_accuracy)\n",
        "\n",
        "    print(\"Epoch: {}; TRAIN LOSS: {:f}; TEST LOSS: {:f}; TEST ACC: {:f}\".format(epoch, avg_loss_train, avg_loss_test, test_accuracy))\n",
        "    "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JDqBfssrn9My",
        "outputId": "db97351d-271b-4a0a-e27d-97d8af803097"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 0; TRAIN LOSS: 1.636449; TEST LOSS: 9.407246; TEST ACC: 0.513300\n",
            "Epoch: 1; TRAIN LOSS: 1.457277; TEST LOSS: 8.506301; TEST ACC: 0.518100\n",
            "Epoch: 2; TRAIN LOSS: 1.436602; TEST LOSS: 8.396645; TEST ACC: 0.521300\n",
            "Epoch: 3; TRAIN LOSS: 1.428265; TEST LOSS: 8.349070; TEST ACC: 0.525700\n",
            "Epoch: 4; TRAIN LOSS: 1.421420; TEST LOSS: 8.277293; TEST ACC: 0.535600\n",
            "Epoch: 5; TRAIN LOSS: 1.411188; TEST LOSS: 8.254973; TEST ACC: 0.531600\n",
            "Epoch: 6; TRAIN LOSS: 1.414217; TEST LOSS: 8.244768; TEST ACC: 0.541900\n",
            "Epoch: 7; TRAIN LOSS: 1.413208; TEST LOSS: 8.253589; TEST ACC: 0.531300\n",
            "Epoch: 8; TRAIN LOSS: 1.404698; TEST LOSS: 8.183398; TEST ACC: 0.535900\n",
            "Epoch: 9; TRAIN LOSS: 1.403784; TEST LOSS: 8.207063; TEST ACC: 0.528600\n",
            "Epoch: 10; TRAIN LOSS: 1.404883; TEST LOSS: 8.191067; TEST ACC: 0.532400\n",
            "Epoch: 11; TRAIN LOSS: 1.404580; TEST LOSS: 8.217682; TEST ACC: 0.530000\n",
            "Epoch: 12; TRAIN LOSS: 1.403468; TEST LOSS: 8.183441; TEST ACC: 0.543000\n",
            "Epoch: 13; TRAIN LOSS: 1.397193; TEST LOSS: 8.144958; TEST ACC: 0.539100\n",
            "Epoch: 14; TRAIN LOSS: 1.398455; TEST LOSS: 8.153561; TEST ACC: 0.545000\n",
            "Epoch: 15; TRAIN LOSS: 1.395632; TEST LOSS: 8.144370; TEST ACC: 0.543300\n",
            "Epoch: 16; TRAIN LOSS: 1.395899; TEST LOSS: 8.146647; TEST ACC: 0.536200\n",
            "Epoch: 17; TRAIN LOSS: 1.396345; TEST LOSS: 8.142195; TEST ACC: 0.545600\n",
            "Epoch: 18; TRAIN LOSS: 1.402489; TEST LOSS: 8.183247; TEST ACC: 0.529500\n",
            "Epoch: 19; TRAIN LOSS: 1.389125; TEST LOSS: 8.109033; TEST ACC: 0.548100\n",
            "Epoch: 20; TRAIN LOSS: 1.388447; TEST LOSS: 8.112716; TEST ACC: 0.542900\n",
            "Epoch: 21; TRAIN LOSS: 1.394542; TEST LOSS: 8.146081; TEST ACC: 0.538200\n",
            "Epoch: 22; TRAIN LOSS: 1.385595; TEST LOSS: 8.084894; TEST ACC: 0.537500\n",
            "Epoch: 23; TRAIN LOSS: 1.393218; TEST LOSS: 8.145460; TEST ACC: 0.536300\n",
            "Epoch: 24; TRAIN LOSS: 1.387122; TEST LOSS: 8.095831; TEST ACC: 0.537800\n",
            "Epoch: 25; TRAIN LOSS: 1.387534; TEST LOSS: 8.098642; TEST ACC: 0.546500\n",
            "Epoch: 26; TRAIN LOSS: 1.391941; TEST LOSS: 8.116910; TEST ACC: 0.543400\n",
            "Epoch: 27; TRAIN LOSS: 1.387032; TEST LOSS: 8.106470; TEST ACC: 0.542200\n",
            "Epoch: 28; TRAIN LOSS: 1.398434; TEST LOSS: 8.166639; TEST ACC: 0.536500\n",
            "Epoch: 29; TRAIN LOSS: 1.388228; TEST LOSS: 8.112757; TEST ACC: 0.541100\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Epoch: {}; TRAIN LOSS: {:f}; TEST LOSS: {:f}; TEST ACC: {:f}\".format(epoch, avg_loss_train, avg_loss_test, test_accuracy))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eJMq8bpobLKe",
        "outputId": "b5cbf24e-1a14-4f4c-ce42-b192320038bd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 29; TRAIN LOSS: 1.959248; TEST LOSS: 11.533354; TEST ACC: 0.531000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(LOSSES_TRAIN)\n",
        "print(LOSSES_EVAL)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "azqcTz1znzYc",
        "outputId": "5de3920b-38c4-4eb4-854b-a58fa23fe625"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[2.105921447277069, 2.017360346657889, 1.9995035693353536, 1.9902146355229982, 1.9809912583049463, 1.982076675307994, 1.975037841164336, 1.9725006672800804, 1.9696760390486037, 1.9724738360667715, 1.9693904275796852, 1.965879384960447, 1.964479182447706, 1.9671884915050195, 1.965451403540008, 1.9641221871181411, 1.9628290217749926, 1.9629997878658527, 1.9619619159065946, 1.9611828789419057, 1.9614038509981973, 1.963080149524066, 1.960030129977635, 1.960712626880529, 1.9595620796388509, 1.9588283105772368, 1.961791565223616, 1.957809610634434, 1.9597946958882468, 1.9592481231202885]\n",
            "[12.327968418598175, 11.86038243174553, 11.766348257660866, 11.710349306464195, 11.663510978221893, 11.659924986958504, 11.623509913682938, 11.60856652855873, 11.589677259325981, 11.602391135692596, 11.594925320148468, 11.571742144227027, 11.551940327882766, 11.57778446674347, 11.572351351380348, 11.560241809487342, 11.556033334136009, 11.55081386268139, 11.542230579257012, 11.540522900223731, 11.542420700192451, 11.550837317109108, 11.529456448554992, 11.542356514930725, 11.530400201678276, 11.527025040984153, 11.541170537471771, 11.51838544011116, 11.532566964626312, 11.53335422873497]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# get the final result\n",
        "net_f = ResNet18(3, Block)\n",
        "# net_f.load_state_dict(torch.load(\"simclr_netf_last_epoch.pt\"))\n",
        "net_g = MLP(512)\n",
        "net = nn.Sequential(net_f, net_g)\n",
        "net.load_state_dict(torch.load(\"simclr_last_epoch.pt\"))\n",
        "net_f.eval()\n",
        "for parameter in net_f.parameters():\n",
        "    parameter.requires_grad = False\n",
        "\n",
        "net_eval = nn.Sequential(net_f, lr)\n",
        "net_eval.to(device)\n",
        "\n",
        "lr.eval()\n",
        "total, correct = 0, 0\n",
        "with torch.no_grad():\n",
        "    for data, label in testset:\n",
        "        data, label = data.to(device), label.to(device)\n",
        "        y_pred = net_eval(data)\n",
        "        # calculate loss \n",
        "        loss = F.cross_entropy(y_pred, label)\n",
        "        cost += loss.item()\n",
        "\n",
        "        total += len(label)\n",
        "        y_hat = torch.argmax(y_pred, dim=1)\n",
        "        correct += torch.sum(torch.eq(y_hat, label)).item()\n",
        "\n",
        "avg_loss_test = cost / len(testset)\n",
        "print(\"The linear evaluation accuracy is:\", correct/total)"
      ],
      "metadata": {
        "id": "Pe6b3lqYrFHr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7f384f84-d4c3-4008-9a07-dfa945586b5b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The linear evaluation accuracy is: 0.5416\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "g3fiOnVGu0Z4"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "8187dac045ec45739fd72ae3d1cb46a9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_c9fe3685608a463e9db8b7fa50a177a5",
              "IPY_MODEL_11852106ef87465a93db649d4743d634",
              "IPY_MODEL_1b75618e8bdb4d1a9750daaf1138d337"
            ],
            "layout": "IPY_MODEL_134178bca01a4082b84161c82eafd98c"
          }
        },
        "c9fe3685608a463e9db8b7fa50a177a5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5b2f7826b2d2424cbfeffe6366e17403",
            "placeholder": "",
            "style": "IPY_MODEL_fe5b64ba0fc84c0e8b57dc093c8e3b7f",
            "value": "100%"
          }
        },
        "11852106ef87465a93db649d4743d634": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a2cf472272c14b09a94fb4f3ba9a0c4e",
            "max": 170498071,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_94570a69aab44f9293fdae90e8a3a07c",
            "value": 170498071
          }
        },
        "1b75618e8bdb4d1a9750daaf1138d337": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2456d48dc14c4dc8aa2325d6390597bd",
            "placeholder": "",
            "style": "IPY_MODEL_5787f9b75b6b4bb494d83f5ba9c359f4",
            "value": " 170498071/170498071 [00:13&lt;00:00, 12590976.60it/s]"
          }
        },
        "134178bca01a4082b84161c82eafd98c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5b2f7826b2d2424cbfeffe6366e17403": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fe5b64ba0fc84c0e8b57dc093c8e3b7f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a2cf472272c14b09a94fb4f3ba9a0c4e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "94570a69aab44f9293fdae90e8a3a07c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "2456d48dc14c4dc8aa2325d6390597bd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5787f9b75b6b4bb494d83f5ba9c359f4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}