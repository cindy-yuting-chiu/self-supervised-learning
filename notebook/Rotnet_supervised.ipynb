{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HtOlr2wE41en"
      },
      "source": [
        "# Training Rotnet with cifar10"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Google Colab setup 1\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "%cd '/content/drive/MyDrive/ecehw/project'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4JkJFx0CUCqH",
        "outputId": "dc7ab999-cd17-437b-b5ab-717f627cf6e0"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "/content/drive/MyDrive/ecehw/project\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Google Colab setup 2\n",
        "import zipfile as zf\n",
        "\n",
        "files = zf.ZipFile(\"tools.zip\", 'r')\n",
        "files.extractall('./')\n",
        "files.close()"
      ],
      "metadata": {
        "id": "WRJBYM_qzTtb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "Nj_B3b7641eq"
      },
      "outputs": [],
      "source": [
        "# import necessary dependencies\n",
        "import argparse\n",
        "import os, sys\n",
        "import time\n",
        "import datetime\n",
        "from tqdm import tqdm_notebook as tqdm\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "\n",
        "from torchvision import datasets, transforms\n",
        "import torchvision\n",
        "\n",
        "from torch.utils.data import DataLoader\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Data Loader"
      ],
      "metadata": {
        "id": "VlCyIzkMbIZX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# the transformation of the test set\n",
        "linear_eval_transform_test = transforms.Compose([\n",
        "            transforms.ToTensor(),\n",
        "            # the normalize numbers are from previous assignment\n",
        "            transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))\n",
        "            ])"
      ],
      "metadata": {
        "id": "hIapX4m47fR5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# load and split data \n",
        "BATCH_SIZE = 128\n",
        "\n",
        "all_train_cifar = datasets.CIFAR10('./data5', train=True, download=True, transform=transforms.ToTensor())\n",
        "#further split train and validation set \n",
        "train_set, val_set = torch.utils.data.random_split(all_train_cifar, [45000, 5000])\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(\n",
        "    train_set,\n",
        "    batch_size = BATCH_SIZE, shuffle=True, )\n",
        "\n",
        "val_loader = torch.utils.data.DataLoader(\n",
        "    val_set,\n",
        "    batch_size = BATCH_SIZE, shuffle=True, )\n",
        "\n",
        "# the testset don't have data augmentation\n",
        "test_loader = torch.utils.data.DataLoader(\n",
        "    datasets.CIFAR10('./data5', train=False, download=True, transform=linear_eval_transform_test),\n",
        "    batch_size = BATCH_SIZE, shuffle=True, )\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z3fTcQYo-25S",
        "outputId": "847455ef-017c-47fd-f8cb-349cd08fd010"
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Network Architecture - Rotnet"
      ],
      "metadata": {
        "id": "i5pWTI5mz2uF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class RotBlock(nn.Module):\n",
        "    def __init__(self, in_planes, out_planes, kernel_size):\n",
        "        super(RotBlock, self).__init__()\n",
        "        padding = int((kernel_size - 1) / 2) # adding this make acc increase from 0.25 to 0.6 up\n",
        "        self.conv = nn.Sequential(\n",
        "            nn.Conv2d(in_planes, out_planes, kernel_size, padding=padding),\n",
        "            nn.BatchNorm2d(out_planes), # adding this make acc increase from 0.25 to 0.6 up\n",
        "            nn.ReLU(True)\n",
        "        )\n",
        "    def forward(self, x):\n",
        "        return self.conv(x)"
      ],
      "metadata": {
        "id": "Oil9iYqGk5Qk"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# separate first 2 block and the last two: refer to to net_f & net_g"
      ],
      "metadata": {
        "id": "i6unOpp4J7t1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class RotNN(nn.Module):\n",
        "    def __init__(self, num_classes = 10, num_inchannels = 3):\n",
        "        super(RotNN, self).__init__()\n",
        "        \n",
        "# RuntimeError: Given groups=1, weight of size [192, 3, 5, 5], \n",
        "# expected input[512, 96, 28, 28] to have 3 channels, but got 96 channels instead\n",
        "\n",
        "        n_channels = 192\n",
        "        n_channels2 = 160\n",
        "        n_channels3 = 96\n",
        "\n",
        "        # # 1st block\n",
        "        # blocks[0].add_module(\"Block1_ConvB1\", BasicBlock(num_inchannels, n_channels, 5))\n",
        "        # blocks[0].add_module(\"Block1_ConvB2\", BasicBlock(n_channels, n_channels2, 1))\n",
        "        # blocks[0].add_module(\"Block1_ConvB3\", BasicBlock(n_channels2, n_channels3, 1))\n",
        "        # blocks[0].add_module(\n",
        "        #     \"Block1_MaxPool\", nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
        "        # )\n",
        "\n",
        "        self.mlpconv1_1 = RotBlock(num_inchannels, n_channels, 5)\n",
        "        self.mlpconv1_2 = RotBlock(n_channels, n_channels2, 1)\n",
        "        self.mlpconv1_3 = RotBlock(n_channels2, n_channels3, 1)\n",
        "        # optional: add max pooling at the end of each block\n",
        "\n",
        "        # # 2nd block\n",
        "        # blocks[1].add_module(\"Block2_ConvB1\", BasicBlock(n_channels3, n_channels, 5))\n",
        "        # blocks[1].add_module(\"Block2_ConvB2\", BasicBlock(n_channels, n_channels, 1))\n",
        "        # blocks[1].add_module(\"Block2_ConvB3\", BasicBlock(n_channels, n_channels, 1))\n",
        "        # blocks[1].add_module(\n",
        "        #     \"Block2_AvgPool\", nn.AvgPool2d(kernel_size=3, stride=2, padding=1)\n",
        "        # )\n",
        "\n",
        "        self.mlpconv2_1 = RotBlock(n_channels3, n_channels, 5)\n",
        "        self.mlpconv2_2 = RotBlock(n_channels, n_channels, 1)\n",
        "        self.mlpconv2_3 = RotBlock(n_channels, n_channels, 1)\n",
        "\n",
        "        # # 3rd block\n",
        "        # blocks[2].add_module(\"Block3_ConvB1\", BasicBlock(n_channels, n_channels, 3))\n",
        "        # blocks[2].add_module(\"Block3_ConvB2\", BasicBlock(n_channels, n_channels, 1))\n",
        "        # blocks[2].add_module(\"Block3_ConvB3\", BasicBlock(n_channels, n_channels, 1))\n",
        "\n",
        "        self.mlpconv3_1 = RotBlock(n_channels, n_channels, 3)\n",
        "        self.mlpconv3_2 = RotBlock(n_channels, n_channels, 1)\n",
        "        self.mlpconv3_3 = RotBlock(n_channels, n_channels, 1)\n",
        "\n",
        "        self.mlpconv4_1 = RotBlock(n_channels, n_channels, 3)\n",
        "        self.mlpconv4_2 = RotBlock(n_channels, n_channels, 1)\n",
        "        self.mlpconv4_3 = RotBlock(n_channels, n_channels, 1)\n",
        "\n",
        "        self.fc1 = nn.Linear(n_channels, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.mlpconv1_3(self.mlpconv1_2(self.mlpconv1_1(x)))\n",
        "        out = self.mlpconv2_3(self.mlpconv2_2(self.mlpconv2_1(out)))\n",
        "        out = self.mlpconv3_3(self.mlpconv3_2(self.mlpconv3_1(out)))\n",
        "        out = self.mlpconv4_3(self.mlpconv4_2(self.mlpconv4_1(out)))\n",
        "\n",
        "        out = F.avg_pool2d(out, (out.size(2), out.size(3))).view(-1, out.size(1)) #  GlobalAveragePooling\n",
        "        #print(out.size())\n",
        "        # alternative: https://pytorch.org/docs/stable/generated/torch.nn.AdaptiveAvgPool2d.html\n",
        "        out = self.fc1(out)\n",
        "        # make sure we apply softmax to general prediction\n",
        "        out = F.softmax(out, dim=1)\n",
        "        return out"
      ],
      "metadata": {
        "id": "S9usnHgek47t"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "vQXV_HOY41ez",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b68f045b-da8f-404d-be8c-4da4dd8d0956"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda:0\n"
          ]
        }
      ],
      "source": [
        "# specify the device for computation\n",
        "\n",
        "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
        "print(device)\n",
        "# net.to(device)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training Pipeline\n"
      ],
      "metadata": {
        "id": "6Qj2hvJg0W37"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "transform_train_rot90 = transforms.Compose(\n",
        "    [\n",
        "    transforms.ToPILImage(),\n",
        "    transforms.RandomRotation(degrees=(90, 90)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))\n",
        "    ])\n",
        "\n",
        "transform_train_rot180 = transforms.Compose(\n",
        "    [\n",
        "    transforms.ToPILImage(),\n",
        "    transforms.RandomRotation(degrees=(180, 180)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))\n",
        "    ])\n",
        "\n",
        "transform_train_rot270 = transforms.Compose(\n",
        "    [\n",
        "    transforms.ToPILImage(),\n",
        "    transforms.RandomRotation(degrees=(270, 270)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))\n",
        "    ])\n"
      ],
      "metadata": {
        "id": "Oc6xhu4Ud8c1"
      },
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# some hyperparameters\n",
        "# total number of training epochs\n",
        "# EPOCHS = 30\n",
        "\n",
        "# current_learning_rate = INITIAL_LR\n",
        "epoch_acc_decay = []\n",
        "# WARMUP_EPOCHS= 100\n",
        "# WARMUPED_LR = 0.1\n",
        "DECAY_EPOCHS = [30, 60, 80]# 50\n",
        "DECAY = 0.2\n",
        "\n",
        "def train_valid (net, EPOCHS, criterion, optimizer, current_learning_rate, current_reg_l2, file_name)-> float:\n",
        "    # start the training/validation process\n",
        "    # the process should take about 5 minutes on a GTX 1070-Ti\n",
        "    # if the code is written efficiently.\n",
        "    best_val_acc = 0\n",
        "    # the folder where the trained model is saved\n",
        "    CHECKPOINT_FOLDER = \"./saved_model_rotnet\"\n",
        "    \n",
        "    print(\"==> Training starts!\")\n",
        "    print(\"=\"*50)\n",
        "    for i in range(0, EPOCHS):\n",
        "        # handle the learning rate scheduler.\n",
        "        # if i % WARMUP_EPOCHS == 0 and i != 0:\n",
        "        #     current_learning_rate = WARMUPED_LR   \n",
        "        #     print(\"Current learning rate has increased to %f\" %current_learning_rate)\n",
        "\n",
        "        # if i % DECAY_EPOCHS == 0 and i > WARMUP_EPOCHS:\n",
        "        if i in DECAY_EPOCHS:\n",
        "            current_learning_rate = current_learning_rate * DECAY\n",
        "            for param_group in optimizer.param_groups:\n",
        "                param_group['lr'] = current_learning_rate\n",
        "            print(\"Current learning rate has decayed to %f\" %current_learning_rate)\n",
        "        \n",
        "        #######################\n",
        "        # your code here\n",
        "        # switch to train mode\n",
        "        net.train()\n",
        "        \n",
        "        #######################\n",
        "        \n",
        "        print(\"Epoch %d:\" %i)\n",
        "        # this help you compute the training accuracy\n",
        "        total_examples = 0\n",
        "        correct_examples = 0\n",
        "        train_loss = 0 # track training loss if you want\n",
        "        \n",
        "        # Train the model for 1 epoch.\n",
        "        for batch_idx, (inputs, targets) in enumerate(train_loader): \n",
        "            # transform inputs into 4 rotation versions: 0, 90, 180, 270\n",
        "            for ind_img in range(len(inputs)): # loop through each image in batch \n",
        "                input_rot0 = inputs[ind_img]\n",
        "                input_rot90 = transform_train_rot90(inputs[ind_img])\n",
        "                input_rot180 = transform_train_rot180(inputs[ind_img])\n",
        "                input_rot270 = transform_train_rot270(inputs[ind_img])\n",
        "\n",
        "                # resize \n",
        "                input_rot0, input_rot90, input_rot180, input_rot270 = torch.unsqueeze(input_rot0, 0), \\\n",
        "                                                                      torch.unsqueeze(input_rot90, 0), \\\n",
        "                                                                      torch.unsqueeze(input_rot180, 0), \\\n",
        "                                                                      torch.unsqueeze(input_rot270, 0)\n",
        "                # if this is the first image in the batch, we just concat the 2 data aug \n",
        "                if ind_img == 0:\n",
        "                    total_tensor = torch.cat((input_rot0, input_rot90, input_rot180, input_rot270), dim=0)\n",
        "                # else append to the previous augmented pair in the batch \n",
        "                else:\n",
        "                    total_tensor = torch.cat((total_tensor, input_rot0, input_rot90, input_rot180, input_rot270), dim=0)            \n",
        "            targets = targets.repeat_interleave(4)  \n",
        "            total_tensor = total_tensor.to(device)\n",
        "            # repeat the original labels for 4 times cuz we rotated for 4 times, and they should have the same class label\n",
        "            targets = targets.to(device)\n",
        "            # compute the output and loss\n",
        "            outputs = net(total_tensor)\n",
        "            loss = criterion(outputs, targets)\n",
        "            # print(batch_idx, loss.item())\n",
        "            \n",
        "            # zero the gradient\n",
        "            optimizer.zero_grad()\n",
        "            \n",
        "            # backpropagation\n",
        "            loss.backward()\n",
        "            \n",
        "            # apply gradient and update the weights\n",
        "            optimizer.step()\n",
        "            \n",
        "            # count the number of correctly predicted samples in the current batch\n",
        "            train_loss += loss.item()\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            correct_examples += (predicted == targets).sum().item()\n",
        "            total_examples += targets.size(0)\n",
        "            \n",
        "            ####################################\n",
        "                    \n",
        "        avg_loss = train_loss / len(train_loader)\n",
        "        avg_acc = correct_examples / total_examples\n",
        "        print(\"Training loss: %.4f, Training accuracy: %.4f\" %(avg_loss, avg_acc))\n",
        "\n",
        "        # Validate on the validation dataset\n",
        "        # switch to eval mode\n",
        "        net.eval()\n",
        "        \n",
        "\n",
        "        # this help you compute the validation accuracy\n",
        "        total_examples = 0\n",
        "        correct_examples = 0\n",
        "        \n",
        "        val_loss = 0 # again, track the validation loss if you want\n",
        "\n",
        "        # disable gradient during validation, which can save GPU memory\n",
        "        with torch.no_grad():\n",
        "            for batch_idx, (inputs, targets) in enumerate(val_loader):\n",
        "                ####################################\n",
        "\n",
        "                for ind_img in range(len(inputs)): # loop through each image in batch \n",
        "                    input_rot0 = inputs[ind_img]\n",
        "                    input_rot90 = transform_train_rot90(inputs[ind_img])\n",
        "                    input_rot180 = transform_train_rot180(inputs[ind_img])\n",
        "                    input_rot270 = transform_train_rot270(inputs[ind_img])\n",
        "\n",
        "                    # resize \n",
        "                    input_rot0, input_rot90, input_rot180, input_rot270 = torch.unsqueeze(input_rot0, 0), \\\n",
        "                                                                          torch.unsqueeze(input_rot90, 0), \\\n",
        "                                                                          torch.unsqueeze(input_rot180, 0), \\\n",
        "                                                                          torch.unsqueeze(input_rot270, 0)\n",
        "                    # if this is the first image in the batch, we just concat the 2 data aug \n",
        "                    if ind_img == 0:\n",
        "                        total_tensor = torch.cat((input_rot0, input_rot90, input_rot180, input_rot270), dim=0)\n",
        "                    # else append to the previous augmented pair in the batch \n",
        "                    else:\n",
        "                        total_tensor = torch.cat((total_tensor, input_rot0, input_rot90, input_rot180, input_rot270), dim=0)            \n",
        "                targets = targets.repeat_interleave(4)  \n",
        "                total_tensor = total_tensor.to(device)\n",
        "                targets = targets.to(device)\n",
        "\n",
        "                # compute the output and loss\n",
        "                outputs = net(total_tensor)\n",
        "                loss = criterion(outputs, targets)\n",
        "\n",
        "                \n",
        "                # count the number of correctly predicted samples in the current batch\n",
        "                val_loss += loss.item()\n",
        "                _, predicted = torch.max(outputs.data, 1)\n",
        "                correct_examples += (predicted == targets).sum().item()\n",
        "                total_examples += targets.size(0)\n",
        "\n",
        "                ####################################\n",
        "\n",
        "        avg_loss = val_loss / len(val_loader)\n",
        "        avg_acc = correct_examples / total_examples\n",
        "        print(\"Validation loss: %.4f, Validation accuracy: %.4f\" % (avg_loss, avg_acc))\n",
        "        epoch_acc_decay.append([avg_loss, avg_acc])\n",
        "\n",
        "        # save the model checkpoint\n",
        "        if avg_acc > best_val_acc:\n",
        "            best_val_acc = avg_acc\n",
        "            if not os.path.exists(CHECKPOINT_FOLDER):\n",
        "                os.makedirs(CHECKPOINT_FOLDER)\n",
        "            print(\"Saving ...\")\n",
        "            torch.save(net.state_dict(), os.path.join(CHECKPOINT_FOLDER, file_name))\n",
        "            \n",
        "        print('')\n",
        "\n",
        "    print(\"=\"*50)\n",
        "    print(f\"==> Optimization finished! Best validation accuracy: {best_val_acc:.4f}\")\n",
        "    return best_val_acc, epoch_acc_decay\n"
      ],
      "metadata": {
        "id": "8TYNhJll5vvH"
      },
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Start Training\n"
      ],
      "metadata": {
        "id": "vVEmmXxinLnr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# clear cuda memory cache\n",
        "import gc\n",
        "torch.cuda.empty_cache()\n",
        "gc.collect()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MzmBhBMRBCWr",
        "outputId": "5c6b5ec2-30b5-4c75-e72a-b9c09e748986"
      },
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {},
          "execution_count": 67
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "hpt_net = RotNN()\n",
        "hpt_net.to(device)\n",
        "hpt_lr = 0.055\n",
        "hpt_regl2 = 3e-05\n",
        "hpt_criterion = nn.CrossEntropyLoss()\n",
        "#hpt_optimizer = optim.Adam(hpt_net.parameters(), lr=hpt_lr, weight_decay = hpt_regl2)\n",
        "hpt_optimizer = optim.SGD(hpt_net.parameters(), lr=hpt_lr, momentum=0.9, weight_decay = hpt_regl2)\n",
        "best_val_acc, loss_acc_LRdecay = train_valid (hpt_net, 50, hpt_criterion, hpt_optimizer, hpt_lr, hpt_regl2, f'lr_{hpt_lr}_bs128.pth')\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l2tchkC19LLg",
        "outputId": "c367e467-325d-4a04-d824-6958fd7c780f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "==> Training starts!\n",
            "==================================================\n",
            "Epoch 0:\n",
            "Training loss: 2.1673, Training accuracy: 0.2853\n",
            "Validation loss: 2.1328, Validation accuracy: 0.3186\n",
            "Saving ...\n",
            "\n",
            "Epoch 1:\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Evaluate on test set"
      ],
      "metadata": {
        "id": "g8Xun6qkCJYa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test = RotNN() \n",
        "test.load_state_dict(torch.load(\"/content/drive/MyDrive/ecehw/project/saved_model_rotnet/hpt_lr_0.01_regL2_5e-05_Rotnet_batch128.pth\"))\n",
        "test.to(device)\n",
        "test.eval()\n",
        "for parameter in test.parameters():\n",
        "    parameter.requires_grad = False"
      ],
      "metadata": {
        "id": "gvBTIFVFs7Gl"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def test_model(mdl, loader):\n",
        "    mdl.eval()\n",
        "    running_correct = 0.\n",
        "    running_loss = 0.\n",
        "    running_total = 0.\n",
        "    with torch.no_grad():\n",
        "        for data,labels in loader:\n",
        "            data = data.to(device); labels = labels.to(device)\n",
        "            outputs = mdl(data)\n",
        "            loss = F.cross_entropy(outputs, labels)\n",
        "            _, preds = outputs.max(1)\n",
        "            running_correct += preds.eq(labels).sum().item()\n",
        "            running_loss += loss.item()\n",
        "            running_total += labels.size(0)\n",
        "    test_acc = running_correct/running_total\n",
        "    test_loss = running_loss/len(loader)\n",
        "    mdl.train()\n",
        "    print\n",
        "    return test_acc, test_loss"
      ],
      "metadata": {
        "id": "NStrenBGu3pn"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_model(test, test_loader)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DBqdwE6j-iHA",
        "outputId": "3e0300e8-4f47-436d-c71b-f2dbf3bc4c66"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.0578, 2.3563357526882767)"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## random code ignore "
      ],
      "metadata": {
        "id": "GKeEXI62CxjF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "HPT_INITIAL_LR = list(np.linspace(0.01, 0.1, 3))\n",
        "#HPT_INITIAL_LR = [0.01, 0.005]\n",
        "#HPT_INITIAL_LR = [0.1]\n",
        "\n",
        "\n",
        "HPT_L2_REG = [5e-5, 3e-5, 1e-5]\n",
        "#HPT_L2_REG = [5e-4]\n",
        "\n",
        "hpt = []\n",
        "EPOCHS = 10\n",
        "hpt_idx = 0\n",
        "\n",
        "for hpt_lr in HPT_INITIAL_LR:\n",
        "    for hpt_regl2 in HPT_L2_REG:\n",
        "        hpt_idx += 1\n",
        "        print (\"No.\" + str(hpt_idx) + \" Combination!\" )\n",
        "        print(f'Current LR: {hpt_lr}, Weight decay: {hpt_regl2}')\n",
        "        hpt_net = RotNN()\n",
        "        hpt_net.to(device)\n",
        "\n",
        "        hpt_criterion = nn.CrossEntropyLoss()\n",
        "        # try playing around with\n",
        "        hpt_optimizer = optim.SGD(hpt_net.parameters(), lr=hpt_lr, momentum=0.9, weight_decay = hpt_regl2)\n",
        "\n",
        "        best_val_acc, loss_acc_LRdecay = train_valid (hpt_net, EPOCHS, hpt_criterion, hpt_optimizer, hpt_lr, hpt_regl2)\n",
        "\n",
        "        hpt.append([hpt_lr, hpt_regl2, best_val_acc])\n",
        "    # net.apply(init_weights)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "P0wVVFU85vqp",
        "outputId": "0d2ff0a1-991e-404b-a400-596fe0bba881"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "No.1 Combination!\n",
            "Current LR: 0.01, Weight decay: 5e-05\n",
            "==> Training starts!\n",
            "==================================================\n",
            "Epoch 0:\n",
            "Training loss: 2.0409, Training accuracy: 0.3046\n",
            "Validation loss: 2.0113, Validation accuracy: 0.3235\n",
            "Saving ...\n",
            "\n",
            "Epoch 1:\n",
            "Training loss: 1.9336, Training accuracy: 0.3965\n",
            "Validation loss: 1.9412, Validation accuracy: 0.3975\n",
            "Saving ...\n",
            "\n",
            "Epoch 2:\n",
            "Training loss: 1.8764, Training accuracy: 0.4605\n",
            "Validation loss: 1.8478, Validation accuracy: 0.4945\n",
            "Saving ...\n",
            "\n",
            "Epoch 3:\n",
            "Training loss: 1.8390, Training accuracy: 0.5023\n",
            "Validation loss: 1.8301, Validation accuracy: 0.5002\n",
            "Saving ...\n",
            "\n",
            "Epoch 4:\n",
            "Training loss: 1.8118, Training accuracy: 0.5316\n",
            "Validation loss: 1.8156, Validation accuracy: 0.5366\n",
            "Saving ...\n",
            "\n",
            "Epoch 5:\n",
            "Training loss: 1.7907, Training accuracy: 0.5553\n",
            "Validation loss: 1.7999, Validation accuracy: 0.5572\n",
            "Saving ...\n",
            "\n",
            "Epoch 6:\n",
            "Training loss: 1.7739, Training accuracy: 0.5766\n",
            "Validation loss: 1.7900, Validation accuracy: 0.5690\n",
            "Saving ...\n",
            "\n",
            "Epoch 7:\n",
            "Training loss: 1.7583, Training accuracy: 0.5951\n",
            "Validation loss: 1.7763, Validation accuracy: 0.5823\n",
            "Saving ...\n",
            "\n",
            "Epoch 8:\n",
            "Training loss: 1.7453, Training accuracy: 0.6093\n",
            "Validation loss: 1.7672, Validation accuracy: 0.5869\n",
            "Saving ...\n",
            "\n",
            "Epoch 9:\n",
            "Training loss: 1.7335, Training accuracy: 0.6239\n",
            "Validation loss: 1.7613, Validation accuracy: 0.5975\n",
            "Saving ...\n",
            "\n",
            "==================================================\n",
            "==> Optimization finished! Best validation accuracy: 0.5975\n",
            "No.2 Combination!\n",
            "Current LR: 0.01, Weight decay: 3e-05\n",
            "==> Training starts!\n",
            "==================================================\n",
            "Epoch 0:\n",
            "Training loss: 2.0414, Training accuracy: 0.3007\n",
            "Validation loss: 2.0160, Validation accuracy: 0.3104\n",
            "Saving ...\n",
            "\n",
            "Epoch 1:\n",
            "Training loss: 1.9409, Training accuracy: 0.3808\n",
            "Validation loss: 1.9191, Validation accuracy: 0.3883\n",
            "Saving ...\n",
            "\n",
            "Epoch 2:\n",
            "Training loss: 1.8825, Training accuracy: 0.4462\n",
            "Validation loss: 1.8714, Validation accuracy: 0.4513\n",
            "Saving ...\n",
            "\n",
            "Epoch 3:\n",
            "Training loss: 1.8464, Training accuracy: 0.4861\n",
            "Validation loss: 1.8419, Validation accuracy: 0.4874\n",
            "Saving ...\n",
            "\n",
            "Epoch 4:\n",
            "Training loss: 1.8172, Training accuracy: 0.5161\n",
            "Validation loss: 1.8236, Validation accuracy: 0.5019\n",
            "Saving ...\n",
            "\n",
            "Epoch 5:\n",
            "Training loss: 1.7949, Training accuracy: 0.5415\n",
            "Validation loss: 1.8022, Validation accuracy: 0.5367\n",
            "Saving ...\n",
            "\n",
            "Epoch 6:\n",
            "Training loss: 1.7766, Training accuracy: 0.5619\n",
            "Validation loss: 1.7910, Validation accuracy: 0.5476\n",
            "Saving ...\n",
            "\n",
            "Epoch 7:\n",
            "Training loss: 1.7613, Training accuracy: 0.5787\n",
            "Validation loss: 1.7768, Validation accuracy: 0.5716\n",
            "Saving ...\n",
            "\n",
            "Epoch 8:\n",
            "Training loss: 1.7475, Training accuracy: 0.5955\n",
            "Validation loss: 1.7615, Validation accuracy: 0.5977\n",
            "Saving ...\n",
            "\n",
            "Epoch 9:\n",
            "Training loss: 1.7350, Training accuracy: 0.6121\n",
            "Validation loss: 1.7535, Validation accuracy: 0.6028\n",
            "Saving ...\n",
            "\n",
            "==================================================\n",
            "==> Optimization finished! Best validation accuracy: 0.6028\n",
            "No.3 Combination!\n",
            "Current LR: 0.01, Weight decay: 1e-05\n",
            "==> Training starts!\n",
            "==================================================\n",
            "Epoch 0:\n",
            "Training loss: 2.0402, Training accuracy: 0.3044\n",
            "Validation loss: 2.0162, Validation accuracy: 0.3003\n",
            "Saving ...\n",
            "\n",
            "Epoch 1:\n",
            "Training loss: 1.9331, Training accuracy: 0.3933\n",
            "Validation loss: 1.9119, Validation accuracy: 0.4106\n",
            "Saving ...\n",
            "\n",
            "Epoch 2:\n",
            "Training loss: 1.8751, Training accuracy: 0.4595\n",
            "Validation loss: 1.8516, Validation accuracy: 0.4887\n",
            "Saving ...\n",
            "\n",
            "Epoch 3:\n",
            "Training loss: 1.8378, Training accuracy: 0.4996\n",
            "Validation loss: 1.8379, Validation accuracy: 0.4958\n",
            "Saving ...\n",
            "\n",
            "Epoch 4:\n",
            "Training loss: 1.8113, Training accuracy: 0.5253\n",
            "Validation loss: 1.8159, Validation accuracy: 0.5225\n",
            "Saving ...\n",
            "\n",
            "Epoch 5:\n",
            "Training loss: 1.7909, Training accuracy: 0.5476\n",
            "Validation loss: 1.7952, Validation accuracy: 0.5438\n",
            "Saving ...\n",
            "\n",
            "Epoch 6:\n",
            "Training loss: 1.7732, Training accuracy: 0.5664\n",
            "Validation loss: 1.7861, Validation accuracy: 0.5533\n",
            "Saving ...\n",
            "\n",
            "Epoch 7:\n",
            "Training loss: 1.7589, Training accuracy: 0.5837\n",
            "Validation loss: 1.7843, Validation accuracy: 0.5650\n",
            "Saving ...\n",
            "\n",
            "Epoch 8:\n",
            "Training loss: 1.7453, Training accuracy: 0.6006\n",
            "Validation loss: 1.7744, Validation accuracy: 0.5739\n",
            "Saving ...\n",
            "\n",
            "Epoch 9:\n",
            "Training loss: 1.7338, Training accuracy: 0.6151\n",
            "Validation loss: 1.7669, Validation accuracy: 0.5887\n",
            "Saving ...\n",
            "\n",
            "==================================================\n",
            "==> Optimization finished! Best validation accuracy: 0.5887\n",
            "No.4 Combination!\n",
            "Current LR: 0.05500000000000001, Weight decay: 5e-05\n",
            "==> Training starts!\n",
            "==================================================\n",
            "Epoch 0:\n",
            "Training loss: 2.0193, Training accuracy: 0.2855\n",
            "Validation loss: 1.9669, Validation accuracy: 0.3474\n",
            "Saving ...\n",
            "\n",
            "Epoch 1:\n",
            "Training loss: 1.9183, Training accuracy: 0.4038\n",
            "Validation loss: 1.8971, Validation accuracy: 0.4320\n",
            "Saving ...\n",
            "\n",
            "Epoch 2:\n",
            "Training loss: 1.8712, Training accuracy: 0.4529\n",
            "Validation loss: 1.8536, Validation accuracy: 0.4706\n",
            "Saving ...\n",
            "\n",
            "Epoch 3:\n",
            "Training loss: 1.8393, Training accuracy: 0.4870\n",
            "Validation loss: 1.8230, Validation accuracy: 0.5065\n",
            "Saving ...\n",
            "\n",
            "Epoch 4:\n",
            "Training loss: 1.8154, Training accuracy: 0.5143\n",
            "Validation loss: 1.8128, Validation accuracy: 0.5159\n",
            "Saving ...\n",
            "\n",
            "Epoch 5:\n",
            "Training loss: 1.7960, Training accuracy: 0.5403\n",
            "Validation loss: 1.7880, Validation accuracy: 0.5571\n",
            "Saving ...\n",
            "\n",
            "Epoch 6:\n",
            "Training loss: 1.7805, Training accuracy: 0.5606\n",
            "Validation loss: 1.7877, Validation accuracy: 0.5540\n",
            "\n",
            "Epoch 7:\n",
            "Training loss: 1.7662, Training accuracy: 0.5864\n",
            "Validation loss: 1.7864, Validation accuracy: 0.5736\n",
            "Saving ...\n",
            "\n",
            "Epoch 8:\n",
            "Training loss: 1.7526, Training accuracy: 0.6069\n",
            "Validation loss: 1.7666, Validation accuracy: 0.5954\n",
            "Saving ...\n",
            "\n",
            "Epoch 9:\n",
            "Training loss: 1.7410, Training accuracy: 0.6258\n",
            "Validation loss: 1.7618, Validation accuracy: 0.6023\n",
            "Saving ...\n",
            "\n",
            "==================================================\n",
            "==> Optimization finished! Best validation accuracy: 0.6023\n",
            "No.5 Combination!\n",
            "Current LR: 0.05500000000000001, Weight decay: 3e-05\n",
            "==> Training starts!\n",
            "==================================================\n",
            "Epoch 0:\n",
            "Training loss: 2.0260, Training accuracy: 0.2694\n",
            "Validation loss: 1.9570, Validation accuracy: 0.3347\n",
            "Saving ...\n",
            "\n",
            "Epoch 1:\n",
            "Training loss: 1.9337, Training accuracy: 0.3799\n",
            "Validation loss: 1.9057, Validation accuracy: 0.4128\n",
            "Saving ...\n",
            "\n",
            "Epoch 2:\n",
            "Training loss: 1.8801, Training accuracy: 0.4459\n",
            "Validation loss: 1.8544, Validation accuracy: 0.4712\n",
            "Saving ...\n",
            "\n",
            "Epoch 3:\n",
            "Training loss: 1.8408, Training accuracy: 0.4881\n",
            "Validation loss: 1.8261, Validation accuracy: 0.5090\n",
            "Saving ...\n",
            "\n",
            "Epoch 4:\n",
            "Training loss: 1.8166, Training accuracy: 0.5137\n",
            "Validation loss: 1.8052, Validation accuracy: 0.5111\n",
            "Saving ...\n",
            "\n",
            "Epoch 5:\n",
            "Training loss: 1.7966, Training accuracy: 0.5377\n",
            "Validation loss: 1.7895, Validation accuracy: 0.5419\n",
            "Saving ...\n",
            "\n",
            "Epoch 6:\n",
            "Training loss: 1.7809, Training accuracy: 0.5566\n",
            "Validation loss: 1.7705, Validation accuracy: 0.5672\n",
            "Saving ...\n",
            "\n",
            "Epoch 7:\n",
            "Training loss: 1.7662, Training accuracy: 0.5772\n",
            "Validation loss: 1.7629, Validation accuracy: 0.5873\n",
            "Saving ...\n",
            "\n",
            "Epoch 8:\n",
            "Training loss: 1.7535, Training accuracy: 0.5986\n",
            "Validation loss: 1.7585, Validation accuracy: 0.5989\n",
            "Saving ...\n",
            "\n",
            "Epoch 9:\n",
            "Training loss: 1.7416, Training accuracy: 0.6162\n",
            "Validation loss: 1.7644, Validation accuracy: 0.5909\n",
            "\n",
            "==================================================\n",
            "==> Optimization finished! Best validation accuracy: 0.5989\n",
            "No.6 Combination!\n",
            "Current LR: 0.05500000000000001, Weight decay: 1e-05\n",
            "==> Training starts!\n",
            "==================================================\n",
            "Epoch 0:\n",
            "Training loss: 2.0175, Training accuracy: 0.2725\n",
            "Validation loss: 1.9882, Validation accuracy: 0.3146\n",
            "Saving ...\n",
            "\n",
            "Epoch 1:\n",
            "Training loss: 1.9242, Training accuracy: 0.3957\n",
            "Validation loss: 1.8999, Validation accuracy: 0.4299\n",
            "Saving ...\n",
            "\n",
            "Epoch 2:\n",
            "Training loss: 1.8728, Training accuracy: 0.4545\n",
            "Validation loss: 1.8487, Validation accuracy: 0.4788\n",
            "Saving ...\n",
            "\n",
            "Epoch 3:\n",
            "Training loss: 1.8379, Training accuracy: 0.4938\n",
            "Validation loss: 1.8172, Validation accuracy: 0.5041\n",
            "Saving ...\n",
            "\n",
            "Epoch 4:\n",
            "Training loss: 1.8132, Training accuracy: 0.5200\n",
            "Validation loss: 1.8036, Validation accuracy: 0.5269\n",
            "Saving ...\n",
            "\n",
            "Epoch 5:\n",
            "Training loss: 1.7926, Training accuracy: 0.5462\n",
            "Validation loss: 1.7865, Validation accuracy: 0.5504\n",
            "Saving ...\n",
            "\n",
            "Epoch 6:\n",
            "Training loss: 1.7760, Training accuracy: 0.5697\n",
            "Validation loss: 1.7779, Validation accuracy: 0.5753\n",
            "Saving ...\n",
            "\n",
            "Epoch 7:\n",
            "Training loss: 1.7609, Training accuracy: 0.5947\n",
            "Validation loss: 1.7555, Validation accuracy: 0.6066\n",
            "Saving ...\n",
            "\n",
            "Epoch 8:\n",
            "Training loss: 1.7478, Training accuracy: 0.6152\n",
            "Validation loss: 1.7557, Validation accuracy: 0.6088\n",
            "Saving ...\n",
            "\n",
            "Epoch 9:\n",
            "Training loss: 1.7345, Training accuracy: 0.6344\n",
            "Validation loss: 1.7475, Validation accuracy: 0.6214\n",
            "Saving ...\n",
            "\n",
            "==================================================\n",
            "==> Optimization finished! Best validation accuracy: 0.6214\n",
            "No.7 Combination!\n",
            "Current LR: 0.1, Weight decay: 5e-05\n",
            "==> Training starts!\n",
            "==================================================\n",
            "Epoch 0:\n",
            "Training loss: 2.0363, Training accuracy: 0.2510\n",
            "Validation loss: 2.0043, Validation accuracy: 0.3109\n",
            "Saving ...\n",
            "\n",
            "Epoch 1:\n",
            "Training loss: 1.9612, Training accuracy: 0.3453\n",
            "Validation loss: 1.9460, Validation accuracy: 0.3709\n",
            "Saving ...\n",
            "\n",
            "Epoch 2:\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-10-10db4e3cffa1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0mhpt_optimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSGD\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhpt_net\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhpt_lr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmomentum\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.9\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight_decay\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhpt_regl2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m         \u001b[0mbest_val_acc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_acc_LRdecay\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_valid\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhpt_net\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mEPOCHS\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhpt_criterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhpt_optimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhpt_lr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhpt_regl2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0mhpt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mhpt_lr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhpt_regl2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbest_val_acc\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-9-dbc4f999d868>\u001b[0m in \u001b[0;36mtrain_valid\u001b[0;34m(net, EPOCHS, criterion, optimizer, current_learning_rate, current_reg_l2)\u001b[0m\n\u001b[1;32m    105\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m             \u001b[0;31m# count the number of correctly predicted samples in the current batch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 107\u001b[0;31m             \u001b[0mtrain_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    108\u001b[0m             \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredicted\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    109\u001b[0m             \u001b[0mcorrect_examples\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mpredicted\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# apply on test set and evaluate on \n"
      ],
      "metadata": {
        "id": "rWT8sYnIj1l_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "hpt_net = RotNN()\n",
        "hpt_net.to(device)\n",
        "\n",
        "hpt_criterion = nn.CrossEntropyLoss()\n",
        "hpt_optimizer = optim.SGD(hpt_net.parameters(), lr=0.1, momentum=0.9, weight_decay = 5e-4)\n",
        "\n",
        "best_val_acc, loss_acc_LRdecay = train_valid (hpt_net, 5, hpt_criterion, hpt_optimizer, 0.1, 5e-4)\n",
        "\n",
        "    "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1MEfrgCl3u3H",
        "outputId": "061b2c9f-739b-4bbb-e964-a95c98e3418c"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "==> Training starts!\n",
            "==================================================\n",
            "Epoch 0:\n",
            "Training loss: 2.0431, Training accuracy: 0.2460\n",
            "Validation loss: 2.0320, Validation accuracy: 0.2663\n",
            "Saving ...\n",
            "\n",
            "Epoch 1:\n",
            "Training loss: 1.9911, Training accuracy: 0.2901\n",
            "Validation loss: 2.0322, Validation accuracy: 0.2933\n",
            "Saving ...\n",
            "\n",
            "Epoch 2:\n",
            "Training loss: 1.9662, Training accuracy: 0.3414\n",
            "Validation loss: 1.9480, Validation accuracy: 0.3599\n",
            "Saving ...\n",
            "\n",
            "Epoch 3:\n",
            "Training loss: 1.9329, Training accuracy: 0.3845\n",
            "Validation loss: 1.9855, Validation accuracy: 0.3333\n",
            "\n",
            "Epoch 4:\n",
            "Training loss: 1.9171, Training accuracy: 0.4022\n",
            "Validation loss: 1.9980, Validation accuracy: 0.3358\n",
            "\n",
            "==================================================\n",
            "==> Optimization finished! Best validation accuracy: 0.3599\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "zcBMzyX4v5U3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(np.arange(0, 20), np.asarray(epoch_acc_decay)[:, 1], marker='.')\n",
        "plt.grid(True)\n",
        "plt.title(\"Epochs v.s. Accuracy with Learning Rate Decay\")\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Validation Accuracy')\n",
        "plt.show()\n",
        "\n",
        "plt.plot(np.arange(0, 20), np.asarray(epoch_acc_decay)[:, 0], marker='.')\n",
        "plt.grid(True)\n",
        "plt.title(\"Epochs v.s. Loss with Learning Rate Decay\")\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Validation Loss')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 573
        },
        "id": "j7yS38Us0Urv",
        "outputId": "5d87226c-662c-43b0-d43a-520b2e1af253"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3.9.7",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    },
    "vscode": {
      "interpreter": {
        "hash": "1e06c53748c14b23090e12b4fccdda9ee8ab5c2813816b27f2e90702be89e9c2"
      }
    },
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}