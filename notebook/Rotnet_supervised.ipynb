{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HtOlr2wE41en"
      },
      "source": [
        "# Training Rotnet with cifar10"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4JkJFx0CUCqH",
        "outputId": "2c0a2a0b-8a8c-4c17-c912-783655d56635"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n",
            "/content/drive/MyDrive/ecehw/project\n"
          ]
        }
      ],
      "source": [
        "# Google Colab setup 1\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "%cd '/content/drive/MyDrive/ecehw/project'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WRJBYM_qzTtb"
      },
      "outputs": [],
      "source": [
        "# Google Colab setup 2\n",
        "import zipfile as zf\n",
        "\n",
        "files = zf.ZipFile(\"tools.zip\", 'r')\n",
        "files.extractall('./')\n",
        "files.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "Nj_B3b7641eq"
      },
      "outputs": [],
      "source": [
        "# import necessary dependencies\n",
        "import argparse\n",
        "import os, sys\n",
        "import time\n",
        "import datetime\n",
        "from tqdm import tqdm_notebook as tqdm\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "\n",
        "from torchvision import datasets, transforms\n",
        "import torchvision\n",
        "\n",
        "from torch.utils.data import DataLoader\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VlCyIzkMbIZX"
      },
      "source": [
        "### Data Loader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "hIapX4m47fR5"
      },
      "outputs": [],
      "source": [
        "# the transformation of the test set\n",
        "linear_eval_transform_test = transforms.Compose([\n",
        "            transforms.ToTensor(),\n",
        "            # the normalize numbers are from previous assignment\n",
        "            transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))\n",
        "            ])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z3fTcQYo-25S",
        "outputId": "f59229ef-fe97-4b74-c2dd-162087d21b3c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n"
          ]
        }
      ],
      "source": [
        "# load and split data \n",
        "BATCH_SIZE = 128\n",
        "\n",
        "all_train_cifar = datasets.CIFAR10('./data6', train=True, download=True, transform=transforms.Compose(\n",
        "    [transforms.ToTensor(), transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))]))\n",
        "#further split train and validation set \n",
        "train_set, val_set = torch.utils.data.random_split(all_train_cifar, [45000, 5000])\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(\n",
        "    train_set,\n",
        "    batch_size = BATCH_SIZE, shuffle=True, )\n",
        "\n",
        "val_loader = torch.utils.data.DataLoader(\n",
        "    val_set,\n",
        "    batch_size = BATCH_SIZE, shuffle=True, )\n",
        "\n",
        "# the testset don't have data augmentation\n",
        "test_loader = torch.utils.data.DataLoader(\n",
        "    datasets.CIFAR10('./data6', train=False, download=True, transform=linear_eval_transform_test),\n",
        "    batch_size = BATCH_SIZE, shuffle=True, )\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i5pWTI5mz2uF"
      },
      "source": [
        "## Network Architecture - Rotnet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "Oil9iYqGk5Qk"
      },
      "outputs": [],
      "source": [
        "class RotBlock(nn.Module):\n",
        "    def __init__(self, in_planes, out_planes, kernel_size):\n",
        "        super(RotBlock, self).__init__()\n",
        "        padding = int((kernel_size - 1) / 2) # adding this make acc increase from 0.25 to 0.6 up\n",
        "        self.conv = nn.Sequential(\n",
        "            nn.Conv2d(in_planes, out_planes, kernel_size, padding=padding),\n",
        "            nn.BatchNorm2d(out_planes), # adding this make acc increase from 0.25 to 0.6 up\n",
        "            nn.ReLU(True)\n",
        "        )\n",
        "    def forward(self, x):\n",
        "        return self.conv(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i6unOpp4J7t1"
      },
      "outputs": [],
      "source": [
        "# separate first 2 block and the last two: refer to to net_f & net_g"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "S9usnHgek47t"
      },
      "outputs": [],
      "source": [
        "class RotNN(nn.Module):\n",
        "    def __init__(self, num_classes = 10, num_inchannels = 3):\n",
        "        super(RotNN, self).__init__()\n",
        "        \n",
        "# RuntimeError: Given groups=1, weight of size [192, 3, 5, 5], \n",
        "# expected input[512, 96, 28, 28] to have 3 channels, but got 96 channels instead\n",
        "\n",
        "        n_channels = 192\n",
        "        n_channels2 = 160\n",
        "        n_channels3 = 96\n",
        "\n",
        "        # # 1st block\n",
        "        # blocks[0].add_module(\"Block1_ConvB1\", BasicBlock(num_inchannels, n_channels, 5))\n",
        "        # blocks[0].add_module(\"Block1_ConvB2\", BasicBlock(n_channels, n_channels2, 1))\n",
        "        # blocks[0].add_module(\"Block1_ConvB3\", BasicBlock(n_channels2, n_channels3, 1))\n",
        "        # blocks[0].add_module(\n",
        "        #     \"Block1_MaxPool\", nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
        "        # )\n",
        "\n",
        "        self.mlpconv1_1 = RotBlock(num_inchannels, n_channels, 5)\n",
        "        self.mlpconv1_2 = RotBlock(n_channels, n_channels2, 1)\n",
        "        self.mlpconv1_3 = RotBlock(n_channels2, n_channels3, 1)\n",
        "        # optional: add max pooling at the end of each block\n",
        "\n",
        "        # # 2nd block\n",
        "        # blocks[1].add_module(\"Block2_ConvB1\", BasicBlock(n_channels3, n_channels, 5))\n",
        "        # blocks[1].add_module(\"Block2_ConvB2\", BasicBlock(n_channels, n_channels, 1))\n",
        "        # blocks[1].add_module(\"Block2_ConvB3\", BasicBlock(n_channels, n_channels, 1))\n",
        "        # blocks[1].add_module(\n",
        "        #     \"Block2_AvgPool\", nn.AvgPool2d(kernel_size=3, stride=2, padding=1)\n",
        "        # )\n",
        "\n",
        "        self.mlpconv2_1 = RotBlock(n_channels3, n_channels, 5)\n",
        "        self.mlpconv2_2 = RotBlock(n_channels, n_channels, 1)\n",
        "        self.mlpconv2_3 = RotBlock(n_channels, n_channels, 1)\n",
        "\n",
        "        # # 3rd block\n",
        "        # blocks[2].add_module(\"Block3_ConvB1\", BasicBlock(n_channels, n_channels, 3))\n",
        "        # blocks[2].add_module(\"Block3_ConvB2\", BasicBlock(n_channels, n_channels, 1))\n",
        "        # blocks[2].add_module(\"Block3_ConvB3\", BasicBlock(n_channels, n_channels, 1))\n",
        "\n",
        "        self.mlpconv3_1 = RotBlock(n_channels, n_channels, 3)\n",
        "        self.mlpconv3_2 = RotBlock(n_channels, n_channels, 1)\n",
        "        self.mlpconv3_3 = RotBlock(n_channels, n_channels, 1)\n",
        "\n",
        "        self.mlpconv4_1 = RotBlock(n_channels, n_channels, 3)\n",
        "        self.mlpconv4_2 = RotBlock(n_channels, n_channels, 1)\n",
        "        self.mlpconv4_3 = RotBlock(n_channels, n_channels, 1)\n",
        "\n",
        "        self.fc1 = nn.Linear(n_channels, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.mlpconv1_3(self.mlpconv1_2(self.mlpconv1_1(x)))\n",
        "        out = self.mlpconv2_3(self.mlpconv2_2(self.mlpconv2_1(out)))\n",
        "        out = self.mlpconv3_3(self.mlpconv3_2(self.mlpconv3_1(out)))\n",
        "        out = self.mlpconv4_3(self.mlpconv4_2(self.mlpconv4_1(out)))\n",
        "\n",
        "        out = F.avg_pool2d(out, (out.size(2), out.size(3))).view(-1, out.size(1)) #  GlobalAveragePooling\n",
        "        #print(out.size())\n",
        "        # alternative: https://pytorch.org/docs/stable/generated/torch.nn.AdaptiveAvgPool2d.html\n",
        "        out = self.fc1(out)\n",
        "        # make sure we apply softmax to general prediction\n",
        "        #out = F.softmax(out, dim=1)\n",
        "        return out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vQXV_HOY41ez",
        "outputId": "8ec55461-3a8c-4435-ea70-1933f12ee7cc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "cuda:0\n"
          ]
        }
      ],
      "source": [
        "# specify the device for computation\n",
        "\n",
        "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
        "print(device)\n",
        "# net.to(device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6Qj2hvJg0W37"
      },
      "source": [
        "## Training Pipeline\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "Oc6xhu4Ud8c1"
      },
      "outputs": [],
      "source": [
        "transform_train_rot90 = transforms.Compose(\n",
        "    [\n",
        "    transforms.ToPILImage(),\n",
        "    transforms.RandomRotation(degrees=(90, 90)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))\n",
        "    ])\n",
        "\n",
        "transform_train_rot180 = transforms.Compose(\n",
        "    [\n",
        "    transforms.ToPILImage(),\n",
        "    transforms.RandomRotation(degrees=(180, 180)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))\n",
        "    ])\n",
        "\n",
        "transform_train_rot270 = transforms.Compose(\n",
        "    [\n",
        "    transforms.ToPILImage(),\n",
        "    transforms.RandomRotation(degrees=(270, 270)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))\n",
        "    ])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "8TYNhJll5vvH"
      },
      "outputs": [],
      "source": [
        "# import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# some hyperparameters\n",
        "# total number of training epochs\n",
        "# EPOCHS = 30\n",
        "\n",
        "# current_learning_rate = INITIAL_LR\n",
        "epoch_acc_decay = []\n",
        "# WARMUP_EPOCHS= 100\n",
        "# WARMUPED_LR = 0.1\n",
        "DECAY_EPOCHS = [30, 60, 80]# 50\n",
        "DECAY = 0.2\n",
        "\n",
        "def train_valid (net, EPOCHS, criterion, optimizer, current_learning_rate, current_reg_l2, file_name)-> float:\n",
        "    # start the training/validation process\n",
        "    # the process should take about 5 minutes on a GTX 1070-Ti\n",
        "    # if the code is written efficiently.\n",
        "    best_val_acc = 0\n",
        "    # the folder where the trained model is saved\n",
        "    CHECKPOINT_FOLDER = \"./saved_model_rotnet\"\n",
        "    \n",
        "    print(\"==> Training starts!\")\n",
        "    print(\"=\"*50)\n",
        "    for i in range(0, EPOCHS):\n",
        "        # handle the learning rate scheduler.\n",
        "        # if i % WARMUP_EPOCHS == 0 and i != 0:\n",
        "        #     current_learning_rate = WARMUPED_LR   \n",
        "        #     print(\"Current learning rate has increased to %f\" %current_learning_rate)\n",
        "\n",
        "        # if i % DECAY_EPOCHS == 0 and i > WARMUP_EPOCHS:\n",
        "        if i in DECAY_EPOCHS:\n",
        "            current_learning_rate = current_learning_rate * DECAY\n",
        "            for param_group in optimizer.param_groups:\n",
        "                param_group['lr'] = current_learning_rate\n",
        "            print(\"Current learning rate has decayed to %f\" %current_learning_rate)\n",
        "        \n",
        "        #######################\n",
        "        # your code here\n",
        "        # switch to train mode\n",
        "        net.train()\n",
        "        \n",
        "        #######################\n",
        "        \n",
        "        print(\"Epoch %d:\" %i)\n",
        "        # this help you compute the training accuracy\n",
        "        total_examples = 0\n",
        "        correct_examples = 0\n",
        "        train_loss = 0 # track training loss if you want\n",
        "        \n",
        "        # Train the model for 1 epoch.\n",
        "        for batch_idx, (inputs, targets) in enumerate(train_loader): \n",
        "            # transform inputs into 4 rotation versions: 0, 90, 180, 270\n",
        "            for ind_img in range(len(inputs)): # loop through each image in batch \n",
        "                input_rot0 = inputs[ind_img]\n",
        "                input_rot90 = transform_train_rot90(inputs[ind_img])\n",
        "                input_rot180 = transform_train_rot180(inputs[ind_img])\n",
        "                input_rot270 = transform_train_rot270(inputs[ind_img])\n",
        "\n",
        "                # resize \n",
        "                input_rot0, input_rot90, input_rot180, input_rot270 = torch.unsqueeze(input_rot0, 0), \\\n",
        "                                                                      torch.unsqueeze(input_rot90, 0), \\\n",
        "                                                                      torch.unsqueeze(input_rot180, 0), \\\n",
        "                                                                      torch.unsqueeze(input_rot270, 0)\n",
        "                # if this is the first image in the batch, we just concat the 2 data aug \n",
        "                if ind_img == 0:\n",
        "                    total_tensor = torch.cat((input_rot0, input_rot90, input_rot180, input_rot270), dim=0)\n",
        "                # else append to the previous augmented pair in the batch \n",
        "                else:\n",
        "                    total_tensor = torch.cat((total_tensor, input_rot0, input_rot90, input_rot180, input_rot270), dim=0)            \n",
        "            targets = targets.repeat_interleave(4)  \n",
        "            total_tensor = total_tensor.to(device)\n",
        "            # repeat the original labels for 4 times cuz we rotated for 4 times, and they should have the same class label\n",
        "            targets = targets.to(device)\n",
        "            # compute the output and loss\n",
        "            outputs = net(total_tensor)\n",
        "            loss = criterion(outputs, targets)\n",
        "            # print(batch_idx, loss.item())\n",
        "            \n",
        "            # zero the gradient\n",
        "            optimizer.zero_grad()\n",
        "            \n",
        "            # backpropagation\n",
        "            loss.backward()\n",
        "            \n",
        "            # apply gradient and update the weights\n",
        "            optimizer.step()\n",
        "            \n",
        "            # count the number of correctly predicted samples in the current batch\n",
        "            train_loss += loss.item()\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            correct_examples += (predicted == targets).sum().item()\n",
        "            total_examples += targets.size(0)\n",
        "            \n",
        "            ####################################\n",
        "                    \n",
        "        avg_loss = train_loss / len(train_loader)\n",
        "        avg_acc = correct_examples / total_examples\n",
        "        print(\"Training loss: %.4f, Training accuracy: %.4f\" %(avg_loss, avg_acc))\n",
        "\n",
        "        # Validate on the validation dataset\n",
        "        # switch to eval mode\n",
        "        net.eval()\n",
        "        \n",
        "\n",
        "        # this help you compute the validation accuracy\n",
        "        total_examples = 0\n",
        "        correct_examples = 0\n",
        "        \n",
        "        val_loss = 0 # again, track the validation loss if you want\n",
        "\n",
        "        # disable gradient during validation, which can save GPU memory\n",
        "        with torch.no_grad():\n",
        "            for batch_idx, (inputs, targets) in enumerate(val_loader):\n",
        "                ####################################\n",
        "\n",
        "                for ind_img in range(len(inputs)): # loop through each image in batch \n",
        "                    input_rot0 = inputs[ind_img]\n",
        "                    input_rot90 = transform_train_rot90(inputs[ind_img])\n",
        "                    input_rot180 = transform_train_rot180(inputs[ind_img])\n",
        "                    input_rot270 = transform_train_rot270(inputs[ind_img])\n",
        "\n",
        "                    # resize \n",
        "                    input_rot0, input_rot90, input_rot180, input_rot270 = torch.unsqueeze(input_rot0, 0), \\\n",
        "                                                                          torch.unsqueeze(input_rot90, 0), \\\n",
        "                                                                          torch.unsqueeze(input_rot180, 0), \\\n",
        "                                                                          torch.unsqueeze(input_rot270, 0)\n",
        "                    # if this is the first image in the batch, we just concat the 2 data aug \n",
        "                    if ind_img == 0:\n",
        "                        total_tensor = torch.cat((input_rot0, input_rot90, input_rot180, input_rot270), dim=0)\n",
        "                    # else append to the previous augmented pair in the batch \n",
        "                    else:\n",
        "                        total_tensor = torch.cat((total_tensor, input_rot0, input_rot90, input_rot180, input_rot270), dim=0)            \n",
        "                targets = targets.repeat_interleave(4)  \n",
        "                total_tensor = total_tensor.to(device)\n",
        "                targets = targets.to(device)\n",
        "\n",
        "                # compute the output and loss\n",
        "                outputs = net(total_tensor)\n",
        "                loss = criterion(outputs, targets)\n",
        "\n",
        "                \n",
        "                # count the number of correctly predicted samples in the current batch\n",
        "                val_loss += loss.item()\n",
        "                _, predicted = torch.max(outputs.data, 1)\n",
        "                correct_examples += (predicted == targets).sum().item()\n",
        "                total_examples += targets.size(0)\n",
        "\n",
        "                ####################################\n",
        "\n",
        "        avg_loss = val_loss / len(val_loader)\n",
        "        avg_acc = correct_examples / total_examples\n",
        "        print(\"Validation loss: %.4f, Validation accuracy: %.4f\" % (avg_loss, avg_acc))\n",
        "        epoch_acc_decay.append([avg_loss, avg_acc])\n",
        "\n",
        "        # save the model checkpoint\n",
        "        if avg_acc > best_val_acc:\n",
        "            best_val_acc = avg_acc\n",
        "            if not os.path.exists(CHECKPOINT_FOLDER):\n",
        "                os.makedirs(CHECKPOINT_FOLDER)\n",
        "            print(\"Saving ...\")\n",
        "            torch.save(net.state_dict(), os.path.join(CHECKPOINT_FOLDER, file_name))\n",
        "            \n",
        "        print('')\n",
        "\n",
        "    print(\"=\"*50)\n",
        "    print(f\"==> Optimization finished! Best validation accuracy: {best_val_acc:.4f}\")\n",
        "    return best_val_acc, epoch_acc_decay\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vVEmmXxinLnr"
      },
      "source": [
        "### Start Training\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MzmBhBMRBCWr",
        "outputId": "79eaa2e3-4fcd-4db5-c8a3-12481e3c6a6c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# clear cuda memory cache\n",
        "import gc\n",
        "torch.cuda.empty_cache()\n",
        "gc.collect()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l2tchkC19LLg",
        "outputId": "17fc03b2-1690-4c70-bb00-cb94f8c2c628"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "==> Training starts!\n",
            "==================================================\n",
            "Epoch 0:\n",
            "Training loss: 1.9475, Training accuracy: 0.2716\n",
            "Validation loss: 1.8949, Validation accuracy: 0.3071\n",
            "Saving ...\n",
            "\n",
            "Epoch 1:\n",
            "Training loss: 1.7150, Training accuracy: 0.3721\n",
            "Validation loss: 1.9721, Validation accuracy: 0.3245\n",
            "Saving ...\n",
            "\n",
            "Epoch 2:\n",
            "Training loss: 1.6035, Training accuracy: 0.4173\n",
            "Validation loss: 1.8217, Validation accuracy: 0.3570\n",
            "Saving ...\n",
            "\n",
            "Epoch 3:\n",
            "Training loss: 1.5228, Training accuracy: 0.4511\n",
            "Validation loss: 1.7787, Validation accuracy: 0.3881\n",
            "Saving ...\n",
            "\n",
            "Epoch 4:\n",
            "Training loss: 1.4632, Training accuracy: 0.4739\n",
            "Validation loss: 1.7286, Validation accuracy: 0.3986\n",
            "Saving ...\n",
            "\n",
            "Epoch 5:\n",
            "Training loss: 1.4042, Training accuracy: 0.4965\n",
            "Validation loss: 1.6700, Validation accuracy: 0.4264\n",
            "Saving ...\n",
            "\n",
            "Epoch 6:\n",
            "Training loss: 1.3449, Training accuracy: 0.5178\n",
            "Validation loss: 1.6460, Validation accuracy: 0.4335\n",
            "Saving ...\n",
            "\n",
            "Epoch 7:\n",
            "Training loss: 1.2951, Training accuracy: 0.5401\n",
            "Validation loss: 1.5495, Validation accuracy: 0.4701\n",
            "Saving ...\n",
            "\n",
            "Epoch 8:\n",
            "Training loss: 1.2467, Training accuracy: 0.5574\n",
            "Validation loss: 1.5609, Validation accuracy: 0.4725\n",
            "Saving ...\n",
            "\n",
            "Epoch 9:\n",
            "Training loss: 1.1989, Training accuracy: 0.5736\n",
            "Validation loss: 2.3653, Validation accuracy: 0.4055\n",
            "\n",
            "Epoch 10:\n",
            "Training loss: 1.1440, Training accuracy: 0.5936\n",
            "Validation loss: 1.7005, Validation accuracy: 0.4627\n",
            "\n",
            "Epoch 11:\n",
            "Training loss: 1.0972, Training accuracy: 0.6098\n",
            "Validation loss: 1.3933, Validation accuracy: 0.5353\n",
            "Saving ...\n",
            "\n",
            "Epoch 12:\n",
            "Training loss: 1.0536, Training accuracy: 0.6262\n",
            "Validation loss: 1.4615, Validation accuracy: 0.5116\n",
            "\n",
            "Epoch 13:\n",
            "Training loss: 1.0109, Training accuracy: 0.6395\n",
            "Validation loss: 1.8711, Validation accuracy: 0.4525\n",
            "\n",
            "Epoch 14:\n",
            "Training loss: 0.9609, Training accuracy: 0.6580\n",
            "Validation loss: 1.6240, Validation accuracy: 0.5036\n",
            "\n",
            "Epoch 15:\n",
            "Training loss: 0.9203, Training accuracy: 0.6715\n",
            "Validation loss: 1.6770, Validation accuracy: 0.5073\n",
            "\n",
            "Epoch 16:\n",
            "Training loss: 0.8760, Training accuracy: 0.6856\n",
            "Validation loss: 1.6478, Validation accuracy: 0.5086\n",
            "\n",
            "Epoch 17:\n",
            "Training loss: 0.8287, Training accuracy: 0.7032\n",
            "Validation loss: 1.8594, Validation accuracy: 0.4796\n",
            "\n",
            "Epoch 18:\n",
            "Training loss: 0.7840, Training accuracy: 0.7190\n",
            "Validation loss: 1.9748, Validation accuracy: 0.4553\n",
            "\n",
            "Epoch 19:\n",
            "Training loss: 0.7492, Training accuracy: 0.7302\n",
            "Validation loss: 1.7509, Validation accuracy: 0.4799\n",
            "\n",
            "Epoch 20:\n",
            "Training loss: 0.7127, Training accuracy: 0.7432\n",
            "Validation loss: 2.1203, Validation accuracy: 0.4560\n",
            "\n",
            "Epoch 21:\n",
            "Training loss: 0.6596, Training accuracy: 0.7631\n",
            "Validation loss: 1.6514, Validation accuracy: 0.5348\n",
            "\n",
            "Epoch 22:\n",
            "Training loss: 0.6226, Training accuracy: 0.7756\n",
            "Validation loss: 2.1739, Validation accuracy: 0.4998\n",
            "\n",
            "Epoch 23:\n",
            "Training loss: 0.5942, Training accuracy: 0.7855\n",
            "Validation loss: 2.5085, Validation accuracy: 0.4402\n",
            "\n",
            "Epoch 24:\n",
            "Training loss: 0.5549, Training accuracy: 0.8001\n",
            "Validation loss: 3.1040, Validation accuracy: 0.4386\n",
            "\n",
            "Epoch 25:\n",
            "Training loss: 0.5126, Training accuracy: 0.8161\n",
            "Validation loss: 2.6301, Validation accuracy: 0.4789\n",
            "\n",
            "Epoch 26:\n",
            "Training loss: 0.4921, Training accuracy: 0.8240\n",
            "Validation loss: 2.6744, Validation accuracy: 0.4526\n",
            "\n",
            "Epoch 27:\n",
            "Training loss: 0.4659, Training accuracy: 0.8317\n",
            "Validation loss: 3.3819, Validation accuracy: 0.4494\n",
            "\n",
            "Epoch 28:\n",
            "Training loss: 0.4220, Training accuracy: 0.8482\n",
            "Validation loss: 3.2656, Validation accuracy: 0.4476\n",
            "\n",
            "Epoch 29:\n",
            "Training loss: 0.3910, Training accuracy: 0.8601\n",
            "Validation loss: 2.3512, Validation accuracy: 0.4896\n",
            "\n",
            "Current learning rate has decayed to 0.011000\n",
            "Epoch 30:\n",
            "Training loss: 0.1821, Training accuracy: 0.9467\n",
            "Validation loss: 1.7991, Validation accuracy: 0.5690\n",
            "Saving ...\n",
            "\n",
            "Epoch 31:\n",
            "Training loss: 0.1031, Training accuracy: 0.9788\n",
            "Validation loss: 1.8835, Validation accuracy: 0.5667\n",
            "\n",
            "Epoch 32:\n",
            "Training loss: 0.0772, Training accuracy: 0.9870\n",
            "Validation loss: 1.9290, Validation accuracy: 0.5684\n",
            "\n",
            "Epoch 33:\n",
            "Training loss: 0.0638, Training accuracy: 0.9897\n",
            "Validation loss: 2.0131, Validation accuracy: 0.5688\n",
            "\n",
            "Epoch 34:\n",
            "Training loss: 0.0533, Training accuracy: 0.9919\n",
            "Validation loss: 2.0391, Validation accuracy: 0.5663\n",
            "\n",
            "Epoch 35:\n",
            "Training loss: 0.0455, Training accuracy: 0.9934\n",
            "Validation loss: 2.0642, Validation accuracy: 0.5672\n",
            "\n",
            "Epoch 36:\n",
            "Training loss: 0.0395, Training accuracy: 0.9948\n",
            "Validation loss: 2.0847, Validation accuracy: 0.5665\n",
            "\n",
            "Epoch 37:\n",
            "Training loss: 0.0345, Training accuracy: 0.9959\n",
            "Validation loss: 2.0996, Validation accuracy: 0.5666\n",
            "\n",
            "Epoch 38:\n",
            "Training loss: 0.0302, Training accuracy: 0.9968\n",
            "Validation loss: 2.1521, Validation accuracy: 0.5670\n",
            "\n",
            "Epoch 39:\n",
            "Training loss: 0.0266, Training accuracy: 0.9976\n",
            "Validation loss: 2.1512, Validation accuracy: 0.5668\n",
            "\n",
            "Epoch 40:\n",
            "Training loss: 0.0237, Training accuracy: 0.9982\n",
            "Validation loss: 2.1583, Validation accuracy: 0.5649\n",
            "\n",
            "Epoch 41:\n",
            "Training loss: 0.0211, Training accuracy: 0.9988\n",
            "Validation loss: 2.1875, Validation accuracy: 0.5666\n",
            "\n",
            "Epoch 42:\n",
            "Training loss: 0.0193, Training accuracy: 0.9991\n",
            "Validation loss: 2.1963, Validation accuracy: 0.5668\n",
            "\n",
            "Epoch 43:\n",
            "Training loss: 0.0171, Training accuracy: 0.9992\n",
            "Validation loss: 2.2119, Validation accuracy: 0.5641\n",
            "\n",
            "Epoch 44:\n",
            "Training loss: 0.0152, Training accuracy: 0.9996\n",
            "Validation loss: 2.2764, Validation accuracy: 0.5635\n",
            "\n",
            "Epoch 45:\n",
            "Training loss: 0.0137, Training accuracy: 0.9997\n",
            "Validation loss: 2.2627, Validation accuracy: 0.5661\n",
            "\n",
            "Epoch 46:\n",
            "Training loss: 0.0127, Training accuracy: 0.9998\n",
            "Validation loss: 2.3002, Validation accuracy: 0.5649\n",
            "\n",
            "Epoch 47:\n",
            "Training loss: 0.0121, Training accuracy: 0.9999\n",
            "Validation loss: 2.2986, Validation accuracy: 0.5639\n",
            "\n",
            "Epoch 48:\n",
            "Training loss: 0.0110, Training accuracy: 0.9999\n",
            "Validation loss: 2.2648, Validation accuracy: 0.5649\n",
            "\n",
            "Epoch 49:\n",
            "Training loss: 0.0104, Training accuracy: 1.0000\n",
            "Validation loss: 2.3245, Validation accuracy: 0.5676\n",
            "\n",
            "==================================================\n",
            "==> Optimization finished! Best validation accuracy: 0.5690\n"
          ]
        }
      ],
      "source": [
        "hpt_net = RotNN()\n",
        "hpt_net.to(device)\n",
        "hpt_lr = 0.05500000000000001\n",
        "hpt_regl2 = 5e-05\n",
        "hpt_criterion = nn.CrossEntropyLoss()\n",
        "#hpt_optimizer = optim.Adam(hpt_net.parameters(), lr=hpt_lr, weight_decay = hpt_regl2)\n",
        "hpt_optimizer = optim.SGD(hpt_net.parameters(), lr=hpt_lr, momentum=0.9, weight_decay = hpt_regl2)\n",
        "best_val_acc, loss_acc_LRdecay = train_valid (hpt_net, 50, hpt_criterion, hpt_optimizer, hpt_lr, hpt_regl2, f'lr_{hpt_lr}_bs128.pth')\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "YwAigRhwiWcY",
        "outputId": "48a24a79-acdf-4718-b768-5862b45f925e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "==> Training starts!\n",
            "==================================================\n",
            "Epoch 0:\n",
            "Training loss: 1.9451, Training accuracy: 0.2749\n",
            "Validation loss: 1.9278, Validation accuracy: 0.3003\n",
            "Saving ...\n",
            "\n",
            "Epoch 1:\n",
            "Training loss: 1.7183, Training accuracy: 0.3716\n",
            "Validation loss: 2.2597, Validation accuracy: 0.2877\n",
            "\n",
            "Epoch 2:\n",
            "Training loss: 1.6107, Training accuracy: 0.4172\n",
            "Validation loss: 1.9342, Validation accuracy: 0.3360\n",
            "Saving ...\n",
            "\n",
            "Epoch 3:\n",
            "Training loss: 1.5260, Training accuracy: 0.4513\n",
            "Validation loss: 1.8484, Validation accuracy: 0.3856\n",
            "Saving ...\n",
            "\n",
            "Epoch 4:\n",
            "Training loss: 1.4644, Training accuracy: 0.4740\n",
            "Validation loss: 1.5974, Validation accuracy: 0.4355\n",
            "Saving ...\n",
            "\n",
            "Epoch 5:\n",
            "Training loss: 1.4057, Training accuracy: 0.4966\n",
            "Validation loss: 2.0546, Validation accuracy: 0.3752\n",
            "\n",
            "Epoch 6:\n",
            "Training loss: 1.3481, Training accuracy: 0.5196\n",
            "Validation loss: 1.5856, Validation accuracy: 0.4592\n",
            "Saving ...\n",
            "\n",
            "Epoch 7:\n",
            "Training loss: 1.3012, Training accuracy: 0.5376\n",
            "Validation loss: 1.7293, Validation accuracy: 0.4470\n",
            "\n",
            "Epoch 8:\n",
            "Training loss: 1.2486, Training accuracy: 0.5550\n",
            "Validation loss: 1.9330, Validation accuracy: 0.4209\n",
            "\n",
            "Epoch 9:\n",
            "Training loss: 1.1986, Training accuracy: 0.5760\n",
            "Validation loss: 1.6658, Validation accuracy: 0.4466\n",
            "\n",
            "Epoch 10:\n",
            "Training loss: 1.1532, Training accuracy: 0.5916\n",
            "Validation loss: 1.5201, Validation accuracy: 0.4804\n",
            "Saving ...\n",
            "\n",
            "Epoch 11:\n",
            "Training loss: 1.1065, Training accuracy: 0.6086\n",
            "Validation loss: 1.7549, Validation accuracy: 0.4476\n",
            "\n",
            "Epoch 12:\n",
            "Training loss: 1.0605, Training accuracy: 0.6241\n",
            "Validation loss: 2.9677, Validation accuracy: 0.3626\n",
            "\n",
            "Epoch 13:\n",
            "Training loss: 1.0154, Training accuracy: 0.6388\n",
            "Validation loss: 1.9239, Validation accuracy: 0.4469\n",
            "\n",
            "Epoch 14:\n",
            "Training loss: 0.9738, Training accuracy: 0.6536\n",
            "Validation loss: 1.4629, Validation accuracy: 0.5161\n",
            "Saving ...\n",
            "\n",
            "Epoch 15:\n",
            "Training loss: 0.9189, Training accuracy: 0.6720\n",
            "Validation loss: 1.5951, Validation accuracy: 0.5056\n",
            "\n",
            "Epoch 16:\n",
            "Training loss: 0.8808, Training accuracy: 0.6852\n",
            "Validation loss: 1.6341, Validation accuracy: 0.5171\n",
            "Saving ...\n",
            "\n",
            "Epoch 17:\n",
            "Training loss: 0.8377, Training accuracy: 0.6997\n",
            "Validation loss: 2.1998, Validation accuracy: 0.4224\n",
            "\n",
            "Epoch 18:\n",
            "Training loss: 0.7925, Training accuracy: 0.7153\n",
            "Validation loss: 2.0104, Validation accuracy: 0.4778\n",
            "\n",
            "Epoch 19:\n",
            "Training loss: 0.7504, Training accuracy: 0.7299\n",
            "Validation loss: 1.7976, Validation accuracy: 0.4789\n",
            "\n",
            "Epoch 20:\n",
            "Training loss: 0.7098, Training accuracy: 0.7444\n",
            "Validation loss: 2.1739, Validation accuracy: 0.4541\n",
            "\n",
            "Epoch 21:\n",
            "Training loss: 0.6642, Training accuracy: 0.7604\n",
            "Validation loss: 1.6565, Validation accuracy: 0.5212\n",
            "Saving ...\n",
            "\n",
            "Epoch 22:\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-14-415834a779f5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m#hpt_optimizer = optim.Adam(hpt_net.parameters(), lr=hpt_lr, weight_decay = hpt_regl2)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mhpt_optimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSGD\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhpt_net\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhpt_lr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmomentum\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.9\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight_decay\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhpt_regl2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mbest_val_acc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_acc_LRdecay\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_valid\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhpt_net\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhpt_criterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhpt_optimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhpt_lr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhpt_regl2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34mf'lr_{hpt_lr}_bs128_3.pth'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-9-f2d54044036a>\u001b[0m in \u001b[0;36mtrain_valid\u001b[0;34m(net, EPOCHS, criterion, optimizer, current_learning_rate, current_reg_l2, file_name)\u001b[0m\n\u001b[1;32m     88\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m             \u001b[0;31m# count the number of correctly predicted samples in the current batch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 90\u001b[0;31m             \u001b[0mtrain_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     91\u001b[0m             \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredicted\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m             \u001b[0mcorrect_examples\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mpredicted\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "hpt_net = RotNN()\n",
        "hpt_net.to(device)\n",
        "hpt_lr = 0.05500000000000001\n",
        "hpt_regl2 = 5e-05\n",
        "hpt_criterion = nn.CrossEntropyLoss()\n",
        "#hpt_optimizer = optim.Adam(hpt_net.parameters(), lr=hpt_lr, weight_decay = hpt_regl2)\n",
        "hpt_optimizer = optim.SGD(hpt_net.parameters(), lr=hpt_lr, momentum=0.9, weight_decay = hpt_regl2)\n",
        "best_val_acc, loss_acc_LRdecay = train_valid (hpt_net, 50, hpt_criterion, hpt_optimizer, hpt_lr, hpt_regl2, f'lr_{hpt_lr}_bs128_3.pth')\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g8Xun6qkCJYa"
      },
      "source": [
        "### Evaluate on test set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "gvBTIFVFs7Gl"
      },
      "outputs": [],
      "source": [
        "test = RotNN() \n",
        "test.load_state_dict(torch.load(\"/content/drive/MyDrive/ecehw/project/saved_model_rotnet/lr_0.05500000000000001_bs128.pth\"))\n",
        "test.to(device)\n",
        "test.eval()\n",
        "for parameter in test.parameters():\n",
        "    parameter.requires_grad = False"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "NStrenBGu3pn"
      },
      "outputs": [],
      "source": [
        "def test_model(mdl, loader):\n",
        "    mdl.eval()\n",
        "    running_correct = 0.\n",
        "    running_loss = 0.\n",
        "    running_total = 0.\n",
        "    with torch.no_grad():\n",
        "        for data,labels in loader:\n",
        "            data = data.to(device); labels = labels.to(device)\n",
        "            outputs = mdl(data)\n",
        "            loss = F.cross_entropy(outputs, labels)\n",
        "            _, preds = outputs.max(1)\n",
        "            running_correct += preds.eq(labels).sum().item()\n",
        "            running_loss += loss.item()\n",
        "            running_total += labels.size(0)\n",
        "    test_acc = running_correct/running_total\n",
        "    test_loss = running_loss/len(loader)\n",
        "    mdl.train()\n",
        "    print\n",
        "    return test_acc, test_loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DBqdwE6j-iHA",
        "outputId": "efe0e8f4-5524-404f-9b07-4ce0cc6d547a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(0.8283, 0.528925406781933)"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "test_model(test, test_loader)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3.8.2 ('bio')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.2"
    },
    "vscode": {
      "interpreter": {
        "hash": "a052e22eaa60398cceee1e32df0cca065df9fb04bdaf615ba1f742e27a886c44"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
